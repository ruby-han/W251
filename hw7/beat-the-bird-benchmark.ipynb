{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install timm","metadata":{"papermill":{"duration":8.151319,"end_time":"2021-06-07T19:35:51.274576","exception":false,"start_time":"2021-06-07T19:35:43.123257","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:20.348845Z","iopub.execute_input":"2021-10-12T03:05:20.349341Z","iopub.status.idle":"2021-10-12T03:05:26.731418Z","shell.execute_reply.started":"2021-10-12T03:05:20.349257Z","shell.execute_reply":"2021-10-12T03:05:26.730535Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tqdm import tqdm_notebook as tqdm\n#import tqdm.notebook import tqdm\nimport cv2\nfrom PIL import Image\nimport numpy as np\nimport pandas as pd\nimport torch\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim import lr_scheduler\nimport timm\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"papermill":{"duration":3.717981,"end_time":"2021-06-07T19:35:55.001999","exception":false,"start_time":"2021-06-07T19:35:51.284018","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:26.734783Z","iopub.execute_input":"2021-10-12T03:05:26.735008Z","iopub.status.idle":"2021-10-12T03:05:28.302624Z","shell.execute_reply.started":"2021-10-12T03:05:26.734980Z","shell.execute_reply":"2021-10-12T03:05:28.301760Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!ls -l ../input/midsw251birds2021","metadata":{"papermill":{"duration":0.654567,"end_time":"2021-06-07T19:35:55.665948","exception":false,"start_time":"2021-06-07T19:35:55.011381","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:28.304833Z","iopub.execute_input":"2021-10-12T03:05:28.305032Z","iopub.status.idle":"2021-10-12T03:05:28.988843Z","shell.execute_reply.started":"2021-10-12T03:05:28.305007Z","shell.execute_reply":"2021-10-12T03:05:28.988026Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"timm_models_list = timm.list_models('*efficientnet*')\n# timm_models_list","metadata":{"execution":{"iopub.status.busy":"2021-10-12T03:05:28.991614Z","iopub.execute_input":"2021-10-12T03:05:28.992104Z","iopub.status.idle":"2021-10-12T03:05:28.998762Z","shell.execute_reply.started":"2021-10-12T03:05:28.992063Z","shell.execute_reply":"2021-10-12T03:05:28.996530Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class args:\n    lr = 0.00009\n    epochs = 30\n    batch_size = 16\n    num_workers = 8\n    folds = 15\n    compeition_name = 'midsw251birds2021'","metadata":{"papermill":{"duration":0.017035,"end_time":"2021-06-07T19:35:55.692802","exception":false,"start_time":"2021-06-07T19:35:55.675767","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.000065Z","iopub.execute_input":"2021-10-12T03:05:29.000490Z","iopub.status.idle":"2021-10-12T03:05:29.009459Z","shell.execute_reply.started":"2021-10-12T03:05:29.000453Z","shell.execute_reply":"2021-10-12T03:05:29.008627Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"alldf = pd.read_csv(f'../input/{args.compeition_name}/train.csv')\nalldf['filename'] = 'train/' + alldf['filename']\n# Split the training dataset into a training and a validation\nvaldf = alldf[::args.folds]\ntrndf = alldf[~alldf.filename.isin(valdf.filename)]\n# Load our test data\ntstdf = pd.read_csv(f'../input/{args.compeition_name}/test.csv')\ntstdf['filename'] = 'test/' + tstdf['filename']\nmetadf = pd.read_csv(f'../input/{args.compeition_name}/metadata.csv')\nmetadf = metadf.set_index('label')\nprint(f'File shapes -- train : {trndf.shape}, valid : {valdf.shape}, test : {tstdf.shape}')\ntrndf.head()","metadata":{"papermill":{"duration":0.093059,"end_time":"2021-06-07T19:35:55.795263","exception":false,"start_time":"2021-06-07T19:35:55.702204","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.010621Z","iopub.execute_input":"2021-10-12T03:05:29.010987Z","iopub.status.idle":"2021-10-12T03:05:29.141035Z","shell.execute_reply.started":"2021-10-12T03:05:29.010958Z","shell.execute_reply":"2021-10-12T03:05:29.140323Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"imgnetmeans = [0.22363983, 0.18190407, 0.2523437 ]\nimgnetstds = [0.32451536, 0.2956294,  0.31335256]\n#Â Using albumentations, check some examples here : https://albumentations.readthedocs.io/en/latest/examples.html \ndef trntransforms():\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.Transpose(p=0.5),\n        A.GaussianBlur(p=0.5),\n        A.RandomBrightnessContrast(),\n        A.VerticalFlip(),\n        ToTensorV2(),\n        ])\n\ndef tsttransforms():\n    return A.Compose([\n        ToTensorV2(),\n    ])\n\nclass BirdDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        self.data = df\n        self.img_dir = f'../input/{args.compeition_name}/'\n        self.transform = transform\n        self.mode = mode\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \n        fname = self.data.iloc[idx]['filename']\n        img_path = f'{self.img_dir}/{fname}'\n        image = cv2.imread(img_path)\n        if self.transform is not None:\n            image = self.transform(image = image)['image']\n        image = image.float() / 255.\n        label = -1 if self.mode=='test' else self.data.iloc[idx]['label']\n        \n        return image, label","metadata":{"papermill":{"duration":0.02155,"end_time":"2021-06-07T19:35:55.827252","exception":false,"start_time":"2021-06-07T19:35:55.805702","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.142369Z","iopub.execute_input":"2021-10-12T03:05:29.142939Z","iopub.status.idle":"2021-10-12T03:05:29.156190Z","shell.execute_reply.started":"2021-10-12T03:05:29.142896Z","shell.execute_reply":"2021-10-12T03:05:29.155398Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define our dataset\ntrndataset = BirdDataset(trndf, 'train', trntransforms())\nvaldataset = BirdDataset(valdf, 'valid', tsttransforms())\ntstdataset = BirdDataset(tstdf, 'test', tsttransforms())","metadata":{"papermill":{"duration":0.016776,"end_time":"2021-06-07T19:35:55.854442","exception":false,"start_time":"2021-06-07T19:35:55.837666","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.157304Z","iopub.execute_input":"2021-10-12T03:05:29.158463Z","iopub.status.idle":"2021-10-12T03:05:29.170328Z","shell.execute_reply.started":"2021-10-12T03:05:29.158409Z","shell.execute_reply":"2021-10-12T03:05:29.169342Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Test the dataset\nimg, label = next(iter(trndataset))\nspecies = metadf.loc[label]['name']\nprint(f'Species : {species}')\n#Image.fromarray(img)\nimgviz = (img * 255).transpose(0, 2).numpy().astype(np.uint8)\nImage.fromarray(imgviz)","metadata":{"papermill":{"duration":0.114321,"end_time":"2021-06-07T19:35:55.979324","exception":false,"start_time":"2021-06-07T19:35:55.865003","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.172081Z","iopub.execute_input":"2021-10-12T03:05:29.172397Z","iopub.status.idle":"2021-10-12T03:05:29.238106Z","shell.execute_reply.started":"2021-10-12T03:05:29.172365Z","shell.execute_reply":"2021-10-12T03:05:29.237315Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"loaderargs = {'num_workers' : args.num_workers, 'batch_size':args.batch_size, 'pin_memory': False, 'drop_last': False}\ntrnloader = DataLoader(trndataset, shuffle = True, **loaderargs)\nvalloader = DataLoader(valdataset, shuffle = False, **loaderargs)\ntstloader = DataLoader(tstdataset, shuffle = False, **loaderargs)","metadata":{"papermill":{"duration":0.019641,"end_time":"2021-06-07T19:35:56.012196","exception":false,"start_time":"2021-06-07T19:35:55.992555","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.240519Z","iopub.execute_input":"2021-10-12T03:05:29.241802Z","iopub.status.idle":"2021-10-12T03:05:29.252412Z","shell.execute_reply.started":"2021-10-12T03:05:29.241769Z","shell.execute_reply":"2021-10-12T03:05:29.251398Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# creates efficientnet-b0 architecture\ndevice = torch.device(\"cuda:0\")\n# model = timm.create_model('efficientnet_b2', pretrained = True)\n# model = timm.create_model('resnet50', pretrained = True)\nmodel = timm.create_model('efficientnet_b3', pretrained = True)\nmodel = model.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n# Loss function\ncriterion = torch.nn.CrossEntropyLoss()\nscheduler = lr_scheduler.StepLR(optimizer, step_size=10)\nnum_epochs = args.epochs\n\n\n# from timm.scheduler.cosine_lr import CosineLRScheduler\n\n# n_epochs = num_epochs\n# n_warmup_epochs = 2\n# n_steps = len(trnloader)\n\n# scheduler = CosineLRScheduler(\n#             optimizer,\n#             t_initial= n_steps * n_epochs + 1,\n#             lr_min=0.01,\n#             warmup_lr_init=0.0005,\n#             warmup_t= n_steps * n_warmup_epochs + 1)\n\n\ndef mixup_loss(criterion, output, labels_a, labels_b, lam):\n    # Partial loss against original labels - partial loss against mixup labels\n    # Assigning fractional label based on the amount of space an image has in resulting image\n    loss = criterion(output, labels_a) * lam + criterion(output, labels_b) * (1.0 - lam)\n    \n    return loss\n\nimport torch.nn.functional as F\nfrom torch.nn.modules.loss import _WeightedLoss\n\nclass LabelSmoothCrossEntropyLoss(_WeightedLoss):\n    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n        super().__init__(weight=weight, reduction=reduction)\n        self.smoothing = smoothing\n        self.weight = weight\n        self.reduction = reduction\n\n    @staticmethod\n    def _smooth_one_hot(targets: torch.Tensor, n_classes: int, smoothing=0.0):\n        assert 0 <= smoothing < 1\n        with torch.no_grad():\n            targets = torch.empty(size=(targets.size(0), n_classes),\n                                  device=targets.device) \\\n                .fill_(smoothing / (n_classes - 1)) \\\n                .scatter_(1, targets.data.unsqueeze(1), 1. - smoothing)\n        return targets\n\n    def forward(self, inputs, targets):\n        targets = LabelSmoothCrossEntropyLoss._smooth_one_hot(targets, inputs.size(-1),\n                                                              self.smoothing)\n        lsm = F.log_softmax(inputs, -1)\n\n        if self.weight is not None:\n            lsm = lsm * self.weight.unsqueeze(0)\n\n        loss = -(targets * lsm).sum(-1)\n\n        if self.reduction == 'sum':\n            loss = loss.sum()\n        elif self.reduction == 'mean':\n            loss = loss.mean()\n\n        return loss\ncriterion = LabelSmoothCrossEntropyLoss(smoothing=0.1)","metadata":{"papermill":{"duration":5.988605,"end_time":"2021-06-07T19:36:02.014139","exception":false,"start_time":"2021-06-07T19:35:56.025534","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:29.255350Z","iopub.execute_input":"2021-10-12T03:05:29.256567Z","iopub.status.idle":"2021-10-12T03:05:32.527174Z","shell.execute_reply.started":"2021-10-12T03:05:29.256523Z","shell.execute_reply":"2021-10-12T03:05:32.526465Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Base code\nsince = time.time()\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n#     scheduler.step()\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(trnloader, total=int(len(trnloader)))\n    for step, batch in enumerate(tk0):\n        inputs = batch[0].to(device, dtype=torch.float)\n        labels = batch[1].to(device).long()\n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n        tk0.set_postfix(train_loss=(running_loss / (step+1)))\n    \n    scheduler.step(epoch=epoch)    \n    \n    valpreds = []\n    model.eval()\n    running_loss = 0.0\n    tkval = tqdm(valloader, total=int(len(valloader)))\n    for step, batch in enumerate(tkval):\n        inputs = batch[0].to(device, dtype=torch.float)\n        labels = batch[1].to(device).long()\n        with torch.no_grad():\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n        valpreds .append(outputs)\n        running_loss += loss.item()\n        tkval.set_postfix(valid_loss=(running_loss / (step+1)))\n    preds = torch.cat(valpreds).argmax(1).detach().cpu().numpy()\n    print(f'Valid accuracy {(valdf.label.values == preds).mean():.4f}')","metadata":{"papermill":{"duration":827.516887,"end_time":"2021-06-07T19:49:49.545225","exception":false,"start_time":"2021-06-07T19:36:02.028338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T03:05:32.530321Z","iopub.execute_input":"2021-10-12T03:05:32.530938Z","iopub.status.idle":"2021-10-12T06:07:51.095550Z","shell.execute_reply.started":"2021-10-12T03:05:32.530908Z","shell.execute_reply":"2021-10-12T06:07:51.094668Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# # With mix up\n# since = time.time()\n# for epoch in range(num_epochs):\n#     print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n# #     scheduler.step()\n#     model.train()\n#     running_loss = 0.0\n#     tk0 = tqdm(trnloader, total=int(len(trnloader)))\n#     for step, batch in enumerate(tk0):\n#         inputs = batch[0].to(device, dtype=torch.float)\n#         labels = batch[1].to(device).long()\n        \n#         # mix up\n#         beta = 1  \n#         lam = np.random.beta(beta, beta)\n#         rand_index = torch.randperm(inputs.size()[0]).to(device) # make an index which reorders the batch\n\n#         labels_a = labels   \n#         labels_b = labels[rand_index]  \n        \n#         inputs_mixed = lam * inputs + (1 - lam) * inputs[rand_index]    # Mixing inputs array with a randomized version of inputs array to produce the mix  \n\n#         optimizer.zero_grad()\n        \n#         outputs = model(inputs_mixed)\n#         loss = mixup_loss(criterion, outputs, labels_a, labels_b, lam)\n        \n#         loss.backward()\n#         optimizer.step()\n#         running_loss += loss.item()\n#         tk0.set_postfix(train_loss=(running_loss / (step+1)))\n    \n#     scheduler.step(epoch=epoch)    \n    \n#     valpreds = []\n#     model.eval()\n#     running_loss = 0.0\n#     tkval = tqdm(valloader, total=int(len(valloader)))\n#     for step, batch in enumerate(tkval):\n#         inputs = batch[0].to(device, dtype=torch.float)\n#         labels = batch[1].to(device).long()\n#         with torch.no_grad():\n#             outputs = model(inputs)\n#             loss = criterion(outputs, labels)\n#         valpreds .append(outputs)\n#         running_loss += loss.item()\n#         tkval.set_postfix(valid_loss=(running_loss / (step+1)))\n#     preds = torch.cat(valpreds).argmax(1).detach().cpu().numpy()\n#     print(f'Valid accuracy {(valdf.label.values == preds).mean():.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-10-12T06:07:51.099053Z","iopub.execute_input":"2021-10-12T06:07:51.099268Z","iopub.status.idle":"2021-10-12T06:07:51.104579Z","shell.execute_reply.started":"2021-10-12T06:07:51.099240Z","shell.execute_reply":"2021-10-12T06:07:51.103416Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Submit \ntstpreds = []\ntktst = tqdm(tstloader, total=int(len(tstloader)))\nfor step, batch in enumerate(tktst):\n    inputs = batch[0].to(device, dtype=torch.float)\n    with torch.no_grad():\n        outputs = model(inputs)\n        tstpreds.append(outputs)\npredicted_labels = torch.cat(tstpreds).argmax(1).detach().cpu().numpy()\ntstdf['label'] = predicted_labels","metadata":{"papermill":{"duration":19.307635,"end_time":"2021-06-07T19:50:08.871976","exception":false,"start_time":"2021-06-07T19:49:49.564341","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T06:07:51.106148Z","iopub.execute_input":"2021-10-12T06:07:51.106483Z","iopub.status.idle":"2021-10-12T06:08:15.594671Z","shell.execute_reply.started":"2021-10-12T06:07:51.106448Z","shell.execute_reply":"2021-10-12T06:08:15.593753Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tstdf.filename = tstdf.filename.str.replace('test/test/', 'test/')\ntstdf.to_csv('submission.csv', index = False)","metadata":{"papermill":{"duration":0.159083,"end_time":"2021-06-07T19:50:09.050992","exception":false,"start_time":"2021-06-07T19:50:08.891909","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T06:08:15.596111Z","iopub.execute_input":"2021-10-12T06:08:15.596488Z","iopub.status.idle":"2021-10-12T06:08:15.635132Z","shell.execute_reply.started":"2021-10-12T06:08:15.596427Z","shell.execute_reply":"2021-10-12T06:08:15.634505Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"tstdf.head()","metadata":{"papermill":{"duration":0.019615,"end_time":"2021-06-07T19:50:09.089968","exception":false,"start_time":"2021-06-07T19:50:09.070353","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-10-12T06:08:15.636512Z","iopub.execute_input":"2021-10-12T06:08:15.636768Z","iopub.status.idle":"2021-10-12T06:08:15.648240Z","shell.execute_reply.started":"2021-10-12T06:08:15.636734Z","shell.execute_reply":"2021-10-12T06:08:15.647456Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}