{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# find_lr function\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DDP\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9dde",
   "metadata": {},
   "source": [
    "### Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39e242",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2296e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95f389",
   "metadata": {},
   "source": [
    "### Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f55eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wandb in /opt/conda/lib/python3.8/site-packages (0.12.5)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.4.3)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.1.24)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: promise<3,>=2.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: pathtools in /opt/conda/lib/python3.8/site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: yaspin>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.1.0)\n",
      "Requirement already satisfied: configparser>=3.8.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.0.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: subprocess32>=3.5.3 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.5.4)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.0.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.0)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from yaspin>=1.0.0->wandb) (1.1.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubyhan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb72e29",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d1a0c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073b7b81",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e18ae51",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "# ARCH = 'resnet152'\n",
    "EPOCHS = 2 #200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=500 #128\n",
    "VAL_BATCH=500 #128\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/hw9/train\"\n",
    "VALDIR=\"/data/hw9/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c0efdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rubyhan/hw9_main/runs/r90npkmp\" target=\"_blank\">morning-vortex-10</a></strong> to <a href=\"https://wandb.ai/rubyhan/hw9_main\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rubyhan/hw9_main/runs/r90npkmp?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f5092130e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hw9_main', \n",
    "           entity='rubyhan', \n",
    "           config = {\n",
    "               \"learning_rate\": LR,\n",
    "               \"epochs\": EPOCHS,\n",
    "               \"batch_size\": TRAIN_BATCH,\n",
    "               \"momentum\": MOMENTUM, \n",
    "               \"weight_decay\": WEIGHT_DECAY,\n",
    "               \"architecture\": ARCH\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf7c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "URL = 'tcp://172.31.26.78:1234'\n",
    "RANK = 0\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                        world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536a0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58857976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88d42a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "        # WITH AMP\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step += 1\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, \"acc1/train\": top1.avg, \"acc5/train\": top5.avg})\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa7d9fd",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c5f0ab4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce30c86a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7504ce7a",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d659923",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f74f06e1",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c005e2dd",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, \n",
    "                                 std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29d54592",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94059b7f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788c0401",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63dc579e",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edf9cf5d",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "319e2d99",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "\n",
    "# Set model on BOTH GPUs\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8dc59b5",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3999d84a",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fae338b",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34dbcdb1",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5275a69",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "854ca1ad",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abfa5fb6",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a0bdf4",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192ae835",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#         val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1502c5db",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fdaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    meter_losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, meter_losses, top1, top5])\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        batch_num += 1\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        meter_losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return log_lrs, losses\n",
    "\n",
    "# logs,losses = find_lr()\n",
    "# plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 26.434 (26.434)\tData  3.603 ( 3.603)\tLoss 7.0067e+00 (7.0067e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  50/1282]\tTime  1.425 ( 2.073)\tData  0.002 ( 0.323)\tLoss 6.6716e+00 (6.8422e+00)\tAcc@1   0.40 (  0.45)\tAcc@5   1.80 (  1.68)\n",
      "Epoch: [0][ 100/1282]\tTime  1.689 ( 1.878)\tData  0.002 ( 0.164)\tLoss 6.1457e+00 (6.6181e+00)\tAcc@1   2.00 (  0.90)\tAcc@5   7.00 (  3.18)\n",
      "Epoch: [0][ 150/1282]\tTime  0.858 ( 1.810)\tData  0.002 ( 0.111)\tLoss 5.8055e+00 (6.4210e+00)\tAcc@1   4.20 (  1.38)\tAcc@5  12.20 (  4.74)\n",
      "Epoch: [0][ 200/1282]\tTime  0.707 ( 1.786)\tData  0.002 ( 0.084)\tLoss 5.6450e+00 (6.2555e+00)\tAcc@1   4.00 (  1.94)\tAcc@5  14.20 (  6.35)\n",
      "Epoch: [0][ 250/1282]\tTime  0.714 ( 1.766)\tData  0.002 ( 0.068)\tLoss 5.3460e+00 (6.1131e+00)\tAcc@1   5.20 (  2.49)\tAcc@5  16.60 (  7.93)\n",
      "Epoch: [0][ 300/1282]\tTime  0.720 ( 1.757)\tData  0.002 ( 0.057)\tLoss 5.0796e+00 (5.9819e+00)\tAcc@1   9.60 (  3.06)\tAcc@5  20.40 (  9.51)\n",
      "Epoch: [0][ 350/1282]\tTime  0.723 ( 1.749)\tData  0.002 ( 0.049)\tLoss 5.1440e+00 (5.8665e+00)\tAcc@1   7.00 (  3.68)\tAcc@5  19.80 ( 11.03)\n",
      "Epoch: [0][ 400/1282]\tTime  0.731 ( 1.742)\tData  0.002 ( 0.043)\tLoss 5.0073e+00 (5.7630e+00)\tAcc@1   8.40 (  4.26)\tAcc@5  24.00 ( 12.49)\n",
      "Epoch: [0][ 450/1282]\tTime  0.729 ( 1.735)\tData  0.002 ( 0.039)\tLoss 4.7608e+00 (5.6679e+00)\tAcc@1  10.80 (  4.85)\tAcc@5  27.00 ( 13.84)\n",
      "Epoch: [0][ 500/1282]\tTime  0.819 ( 1.734)\tData  0.096 ( 0.035)\tLoss 4.8139e+00 (5.5762e+00)\tAcc@1  10.60 (  5.46)\tAcc@5  26.00 ( 15.19)\n",
      "Epoch: [0][ 550/1282]\tTime  0.727 ( 1.734)\tData  0.002 ( 0.033)\tLoss 4.7005e+00 (5.4935e+00)\tAcc@1  12.40 (  6.03)\tAcc@5  26.80 ( 16.44)\n",
      "Epoch: [0][ 600/1282]\tTime  0.745 ( 1.734)\tData  0.002 ( 0.031)\tLoss 4.6151e+00 (5.4138e+00)\tAcc@1  11.00 (  6.64)\tAcc@5  28.20 ( 17.69)\n",
      "Epoch: [0][ 650/1282]\tTime  0.715 ( 1.728)\tData  0.003 ( 0.028)\tLoss 4.3703e+00 (5.3377e+00)\tAcc@1  15.60 (  7.25)\tAcc@5  35.60 ( 18.94)\n",
      "Epoch: [0][ 700/1282]\tTime  0.727 ( 1.723)\tData  0.003 ( 0.027)\tLoss 4.3367e+00 (5.2660e+00)\tAcc@1  14.80 (  7.83)\tAcc@5  36.60 ( 20.11)\n",
      "Epoch: [0][ 750/1282]\tTime  0.723 ( 1.719)\tData  0.003 ( 0.025)\tLoss 4.4239e+00 (5.2005e+00)\tAcc@1  15.60 (  8.39)\tAcc@5  32.60 ( 21.22)\n",
      "Epoch: [0][ 800/1282]\tTime  0.725 ( 1.717)\tData  0.002 ( 0.024)\tLoss 3.9914e+00 (5.1358e+00)\tAcc@1  19.60 (  8.94)\tAcc@5  42.00 ( 22.28)\n",
      "Epoch: [0][ 850/1282]\tTime  0.957 ( 1.715)\tData  0.002 ( 0.022)\tLoss 3.8502e+00 (5.0722e+00)\tAcc@1  22.60 (  9.50)\tAcc@5  43.40 ( 23.37)\n",
      "Epoch: [0][ 900/1282]\tTime  0.710 ( 1.713)\tData  0.002 ( 0.021)\tLoss 3.9224e+00 (5.0119e+00)\tAcc@1  20.20 ( 10.07)\tAcc@5  40.80 ( 24.41)\n",
      "Epoch: [0][ 950/1282]\tTime  0.730 ( 1.713)\tData  0.002 ( 0.020)\tLoss 3.7741e+00 (4.9541e+00)\tAcc@1  24.60 ( 10.63)\tAcc@5  44.00 ( 25.42)\n",
      "Epoch: [0][1000/1282]\tTime  0.719 ( 1.711)\tData  0.002 ( 0.019)\tLoss 3.9099e+00 (4.9000e+00)\tAcc@1  21.80 ( 11.18)\tAcc@5  43.20 ( 26.36)\n",
      "Epoch: [0][1050/1282]\tTime  0.723 ( 1.708)\tData  0.002 ( 0.019)\tLoss 3.9678e+00 (4.8475e+00)\tAcc@1  20.00 ( 11.71)\tAcc@5  44.20 ( 27.29)\n",
      "Epoch: [0][1100/1282]\tTime  0.738 ( 1.708)\tData  0.002 ( 0.018)\tLoss 3.6270e+00 (4.7969e+00)\tAcc@1  24.40 ( 12.23)\tAcc@5  48.80 ( 28.19)\n",
      "Epoch: [0][1150/1282]\tTime  0.711 ( 1.707)\tData  0.002 ( 0.018)\tLoss 3.5244e+00 (4.7472e+00)\tAcc@1  24.80 ( 12.76)\tAcc@5  51.60 ( 29.07)\n",
      "Epoch: [0][1200/1282]\tTime  0.726 ( 1.706)\tData  0.003 ( 0.017)\tLoss 3.4348e+00 (4.6982e+00)\tAcc@1  27.20 ( 13.29)\tAcc@5  55.40 ( 29.93)\n",
      "Epoch: [0][1250/1282]\tTime  0.718 ( 1.704)\tData  0.002 ( 0.017)\tLoss 3.5148e+00 (4.6514e+00)\tAcc@1  27.40 ( 13.81)\tAcc@5  52.20 ( 30.78)\n",
      "Test: [ 0/50]\tTime  8.199 ( 8.199)\tLoss 3.8968e+00 (3.8968e+00)\tAcc@1  21.20 ( 21.20)\tAcc@5  45.40 ( 45.40)\n",
      " * Acc@1 21.216 Acc@5 44.132\n",
      "lr: [0.05]\n",
      "Epoch: [1][   0/1282]\tTime  5.547 ( 5.547)\tData  3.640 ( 3.640)\tLoss 3.4493e+00 (3.4493e+00)\tAcc@1  26.00 ( 26.00)\tAcc@5  53.00 ( 53.00)\n",
      "Epoch: [1][  50/1282]\tTime  2.704 ( 1.729)\tData  0.708 ( 0.490)\tLoss 3.3230e+00 (3.3544e+00)\tAcc@1  32.40 ( 29.54)\tAcc@5  53.40 ( 54.17)\n",
      "Epoch: [1][ 100/1282]\tTime  2.615 ( 1.701)\tData  0.002 ( 0.294)\tLoss 3.2934e+00 (3.3088e+00)\tAcc@1  31.60 ( 30.10)\tAcc@5  55.40 ( 55.33)\n",
      "Epoch: [1][ 150/1282]\tTime  2.501 ( 1.683)\tData  0.002 ( 0.218)\tLoss 3.2471e+00 (3.2727e+00)\tAcc@1  31.20 ( 30.60)\tAcc@5  57.80 ( 55.97)\n",
      "Epoch: [1][ 200/1282]\tTime  2.372 ( 1.673)\tData  0.002 ( 0.240)\tLoss 3.1002e+00 (3.2498e+00)\tAcc@1  32.40 ( 30.92)\tAcc@5  59.60 ( 56.40)\n",
      "Epoch: [1][ 250/1282]\tTime  2.635 ( 1.667)\tData  0.002 ( 0.206)\tLoss 3.0834e+00 (3.2310e+00)\tAcc@1  33.40 ( 31.25)\tAcc@5  60.20 ( 56.74)\n",
      "Epoch: [1][ 300/1282]\tTime  1.906 ( 1.662)\tData  0.002 ( 0.183)\tLoss 3.2246e+00 (3.2115e+00)\tAcc@1  31.20 ( 31.55)\tAcc@5  53.20 ( 57.14)\n",
      "Epoch: [1][ 350/1282]\tTime  0.809 ( 1.657)\tData  0.100 ( 0.227)\tLoss 3.2132e+00 (3.1954e+00)\tAcc@1  31.20 ( 31.80)\tAcc@5  56.00 ( 57.42)\n",
      "Epoch: [1][ 400/1282]\tTime  0.822 ( 1.655)\tData  0.099 ( 0.269)\tLoss 3.1827e+00 (3.1799e+00)\tAcc@1  34.00 ( 32.03)\tAcc@5  61.00 ( 57.72)\n",
      "Epoch: [1][ 450/1282]\tTime  0.815 ( 1.657)\tData  0.100 ( 0.262)\tLoss 3.0696e+00 (3.1651e+00)\tAcc@1  32.20 ( 32.30)\tAcc@5  59.60 ( 58.02)\n",
      "Epoch: [1][ 500/1282]\tTime  1.326 ( 1.659)\tData  0.605 ( 0.248)\tLoss 3.1798e+00 (3.1497e+00)\tAcc@1  32.60 ( 32.55)\tAcc@5  58.00 ( 58.28)\n",
      "Epoch: [1][ 550/1282]\tTime  0.862 ( 1.661)\tData  0.097 ( 0.250)\tLoss 3.1796e+00 (3.1359e+00)\tAcc@1  32.80 ( 32.78)\tAcc@5  58.20 ( 58.54)\n",
      "Epoch: [1][ 600/1282]\tTime  0.818 ( 1.662)\tData  0.097 ( 0.233)\tLoss 3.1830e+00 (3.1231e+00)\tAcc@1  32.20 ( 32.99)\tAcc@5  57.00 ( 58.73)\n",
      "Epoch: [1][ 650/1282]\tTime  0.857 ( 1.660)\tData  0.095 ( 0.219)\tLoss 2.7891e+00 (3.1082e+00)\tAcc@1  39.20 ( 33.24)\tAcc@5  65.20 ( 58.99)\n",
      "Epoch: [1][ 700/1282]\tTime  0.809 ( 1.658)\tData  0.099 ( 0.209)\tLoss 2.9416e+00 (3.0937e+00)\tAcc@1  34.60 ( 33.47)\tAcc@5  60.60 ( 59.26)\n",
      "Epoch: [1][ 750/1282]\tTime  1.002 ( 1.657)\tData  0.284 ( 0.201)\tLoss 3.1873e+00 (3.0840e+00)\tAcc@1  32.20 ( 33.61)\tAcc@5  58.20 ( 59.42)\n",
      "Epoch: [1][ 800/1282]\tTime  0.810 ( 1.657)\tData  0.095 ( 0.192)\tLoss 2.8454e+00 (3.0708e+00)\tAcc@1  37.00 ( 33.81)\tAcc@5  59.00 ( 59.66)\n",
      "Epoch: [1][ 850/1282]\tTime  0.818 ( 1.655)\tData  0.096 ( 0.184)\tLoss 2.7063e+00 (3.0570e+00)\tAcc@1  38.60 ( 34.03)\tAcc@5  65.60 ( 59.91)\n",
      "Epoch: [1][ 900/1282]\tTime  0.729 ( 1.656)\tData  0.003 ( 0.175)\tLoss 2.8047e+00 (3.0443e+00)\tAcc@1  36.20 ( 34.22)\tAcc@5  63.60 ( 60.12)\n",
      "Epoch: [1][ 950/1282]\tTime  0.731 ( 1.655)\tData  0.002 ( 0.166)\tLoss 2.6076e+00 (3.0323e+00)\tAcc@1  42.20 ( 34.43)\tAcc@5  68.00 ( 60.36)\n",
      "Epoch: [1][1000/1282]\tTime  0.723 ( 1.655)\tData  0.003 ( 0.159)\tLoss 2.8083e+00 (3.0212e+00)\tAcc@1  38.60 ( 34.62)\tAcc@5  65.80 ( 60.55)\n",
      "Epoch: [1][1050/1282]\tTime  0.731 ( 1.654)\tData  0.002 ( 0.151)\tLoss 2.9353e+00 (3.0107e+00)\tAcc@1  37.20 ( 34.81)\tAcc@5  63.60 ( 60.74)\n",
      "Epoch: [1][1100/1282]\tTime  0.724 ( 1.655)\tData  0.002 ( 0.144)\tLoss 2.6484e+00 (2.9990e+00)\tAcc@1  43.60 ( 35.01)\tAcc@5  68.60 ( 60.95)\n",
      "Epoch: [1][1150/1282]\tTime  0.727 ( 1.655)\tData  0.002 ( 0.139)\tLoss 2.6606e+00 (2.9873e+00)\tAcc@1  39.40 ( 35.21)\tAcc@5  66.20 ( 61.17)\n",
      "Epoch: [1][1200/1282]\tTime  0.818 ( 1.654)\tData  0.099 ( 0.135)\tLoss 2.5509e+00 (2.9745e+00)\tAcc@1  45.00 ( 35.42)\tAcc@5  70.00 ( 61.38)\n",
      "Epoch: [1][1250/1282]\tTime  0.727 ( 1.654)\tData  0.002 ( 0.137)\tLoss 2.7120e+00 (2.9636e+00)\tAcc@1  39.80 ( 35.61)\tAcc@5  67.20 ( 61.56)\n",
      "Test: [ 0/50]\tTime  4.675 ( 4.675)\tLoss 3.1141e+00 (3.1141e+00)\tAcc@1  32.80 ( 32.80)\tAcc@5  60.20 ( 60.20)\n",
      " * Acc@1 32.632 Acc@5 58.672\n",
      "lr: [0.0]\n",
      "CPU times: user 1h 40min 53s, sys: 35min 38s, total: 2h 16min 31s\n",
      "Wall time: 1h 14min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# start = time.time()\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})\n",
    "    \n",
    "# print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adc68068",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/data/runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
