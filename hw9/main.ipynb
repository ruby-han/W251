{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# find_lr function\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DDP\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9dde",
   "metadata": {},
   "source": [
    "### Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39e242",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2296e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95f389",
   "metadata": {},
   "source": [
    "### Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f55eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubyhan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb72e29",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d1a0c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073b7b81",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e18ae51",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "# ARCH = 'resnet152'\n",
    "EPOCHS = 2 #200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=500 #128\n",
    "VAL_BATCH=500 #128\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/hw9/train\"\n",
    "VALDIR=\"/data/hw9/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c0efdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rubyhan/hw9_main/runs/1h2k1k6t\" target=\"_blank\">sleek-music-8</a></strong> to <a href=\"https://wandb.ai/rubyhan/hw9_main\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rubyhan/hw9_main/runs/1h2k1k6t?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f8844fc5b80>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hw9_main', \n",
    "           entity='rubyhan', \n",
    "           config = {\n",
    "               \"learning_rate\": LR,\n",
    "               \"epochs\": EPOCHS,\n",
    "               \"batch_size\": TRAIN_BATCH,\n",
    "               \"momentum\": MOMENTUM, \n",
    "               \"weight_decay\": WEIGHT_DECAY,\n",
    "               \"architecture\": ARCH\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf7c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "URL = 'tcp://172.31.26.78:1234'\n",
    "RANK = 0\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                        world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "536a0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "33b36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58857976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88d42a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "        # WITH AMP\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step += 1\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, \"acc1/train\": top1.avg, \"acc5/train\": top5.avg})\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afa7d9fd",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c5f0ab4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce30c86a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7504ce7a",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d659923",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f74f06e1",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c005e2dd",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, \n",
    "                                 std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29d54592",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94059b7f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "788c0401",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63dc579e",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edf9cf5d",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "319e2d99",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "\n",
    "# Set model on BOTH GPUs\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8dc59b5",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3999d84a",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9fae338b",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34dbcdb1",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5275a69",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "854ca1ad",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abfa5fb6",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a0bdf4",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "192ae835",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1502c5db",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fdaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    meter_losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, meter_losses, top1, top5])\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        batch_num += 1\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        meter_losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return log_lrs, losses\n",
    "\n",
    "# logs,losses = find_lr()\n",
    "# plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 15.347 (15.347)\tData  3.942 ( 3.942)\tLoss 7.0066e+00 (7.0066e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  50/1282]\tTime  0.695 ( 1.826)\tData  0.003 ( 0.938)\tLoss 6.7108e+00 (6.8437e+00)\tAcc@1   0.60 (  0.48)\tAcc@5   2.40 (  1.63)\n",
      "Epoch: [0][ 100/1282]\tTime  0.672 ( 1.738)\tData  0.002 ( 0.949)\tLoss 6.1412e+00 (6.6136e+00)\tAcc@1   2.00 (  0.94)\tAcc@5   6.40 (  3.13)\n",
      "Epoch: [0][ 150/1282]\tTime  0.702 ( 1.703)\tData  0.002 ( 0.941)\tLoss 5.8201e+00 (6.4211e+00)\tAcc@1   3.80 (  1.39)\tAcc@5  10.40 (  4.64)\n",
      "Epoch: [0][ 200/1282]\tTime  0.692 ( 1.681)\tData  0.002 ( 0.937)\tLoss 5.6502e+00 (6.2552e+00)\tAcc@1   4.60 (  1.98)\tAcc@5  12.60 (  6.31)\n",
      "Epoch: [0][ 250/1282]\tTime  0.678 ( 1.671)\tData  0.003 ( 0.937)\tLoss 5.3398e+00 (6.1112e+00)\tAcc@1   5.20 (  2.52)\tAcc@5  15.80 (  7.88)\n",
      "Epoch: [0][ 300/1282]\tTime  0.680 ( 1.665)\tData  0.002 ( 0.936)\tLoss 5.1088e+00 (5.9808e+00)\tAcc@1   9.60 (  3.14)\tAcc@5  21.40 (  9.47)\n",
      "Epoch: [0][ 350/1282]\tTime  0.711 ( 1.662)\tData  0.002 ( 0.937)\tLoss 5.2421e+00 (5.8673e+00)\tAcc@1   8.20 (  3.71)\tAcc@5  19.20 ( 10.99)\n",
      "Epoch: [0][ 400/1282]\tTime  0.680 ( 1.660)\tData  0.002 ( 0.937)\tLoss 5.0232e+00 (5.7696e+00)\tAcc@1   8.80 (  4.25)\tAcc@5  23.20 ( 12.35)\n",
      "Epoch: [0][ 450/1282]\tTime  0.689 ( 1.657)\tData  0.002 ( 0.936)\tLoss 4.8227e+00 (5.6761e+00)\tAcc@1  11.60 (  4.81)\tAcc@5  26.60 ( 13.67)\n",
      "Epoch: [0][ 500/1282]\tTime  0.680 ( 1.657)\tData  0.002 ( 0.938)\tLoss 4.8572e+00 (5.5873e+00)\tAcc@1   9.40 (  5.39)\tAcc@5  24.40 ( 14.96)\n",
      "Epoch: [0][ 550/1282]\tTime  0.684 ( 1.656)\tData  0.002 ( 0.939)\tLoss 4.8014e+00 (5.5070e+00)\tAcc@1  11.00 (  5.94)\tAcc@5  24.60 ( 16.20)\n",
      "Epoch: [0][ 600/1282]\tTime  0.688 ( 1.656)\tData  0.002 ( 0.939)\tLoss 4.6472e+00 (5.4286e+00)\tAcc@1  10.80 (  6.52)\tAcc@5  29.80 ( 17.45)\n",
      "Epoch: [0][ 650/1282]\tTime  0.685 ( 1.655)\tData  0.002 ( 0.939)\tLoss 4.4695e+00 (5.3538e+00)\tAcc@1  14.40 (  7.14)\tAcc@5  34.20 ( 18.69)\n",
      "Epoch: [0][ 700/1282]\tTime  0.717 ( 1.654)\tData  0.002 ( 0.940)\tLoss 4.3405e+00 (5.2827e+00)\tAcc@1  15.00 (  7.71)\tAcc@5  34.00 ( 19.82)\n",
      "Epoch: [0][ 750/1282]\tTime  0.681 ( 1.654)\tData  0.002 ( 0.940)\tLoss 4.3912e+00 (5.2175e+00)\tAcc@1  15.20 (  8.27)\tAcc@5  33.80 ( 20.90)\n",
      "Epoch: [0][ 800/1282]\tTime  0.688 ( 1.654)\tData  0.002 ( 0.941)\tLoss 4.0797e+00 (5.1541e+00)\tAcc@1  18.40 (  8.82)\tAcc@5  39.60 ( 21.95)\n",
      "Epoch: [0][ 850/1282]\tTime  0.693 ( 1.652)\tData  0.002 ( 0.940)\tLoss 3.8783e+00 (5.0916e+00)\tAcc@1  21.80 (  9.38)\tAcc@5  41.60 ( 23.03)\n",
      "Epoch: [0][ 900/1282]\tTime  0.683 ( 1.651)\tData  0.002 ( 0.940)\tLoss 3.9550e+00 (5.0318e+00)\tAcc@1  20.80 (  9.96)\tAcc@5  41.80 ( 24.06)\n",
      "Epoch: [0][ 950/1282]\tTime  0.683 ( 1.650)\tData  0.002 ( 0.939)\tLoss 3.7965e+00 (4.9746e+00)\tAcc@1  23.60 ( 10.50)\tAcc@5  44.80 ( 25.06)\n",
      "Epoch: [0][1000/1282]\tTime  0.683 ( 1.650)\tData  0.002 ( 0.939)\tLoss 4.0002e+00 (4.9208e+00)\tAcc@1  19.20 ( 11.05)\tAcc@5  43.20 ( 26.01)\n",
      "Epoch: [0][1050/1282]\tTime  0.685 ( 1.650)\tData  0.003 ( 0.939)\tLoss 4.0026e+00 (4.8684e+00)\tAcc@1  19.40 ( 11.57)\tAcc@5  43.00 ( 26.92)\n",
      "Epoch: [0][1100/1282]\tTime  0.717 ( 1.649)\tData  0.002 ( 0.940)\tLoss 3.6498e+00 (4.8178e+00)\tAcc@1  24.20 ( 12.09)\tAcc@5  47.60 ( 27.83)\n",
      "Epoch: [0][1150/1282]\tTime  0.690 ( 1.649)\tData  0.002 ( 0.940)\tLoss 3.6269e+00 (4.7685e+00)\tAcc@1  21.40 ( 12.61)\tAcc@5  50.00 ( 28.71)\n",
      "Epoch: [0][1200/1282]\tTime  0.716 ( 1.650)\tData  0.003 ( 0.940)\tLoss 3.4436e+00 (4.7199e+00)\tAcc@1  27.40 ( 13.14)\tAcc@5  52.00 ( 29.58)\n",
      "Epoch: [0][1250/1282]\tTime  0.714 ( 1.650)\tData  0.003 ( 0.940)\tLoss 3.5460e+00 (4.6735e+00)\tAcc@1  26.40 ( 13.64)\tAcc@5  50.80 ( 30.43)\n",
      "Test: [  0/100]\tTime  8.213 ( 8.213)\tLoss 3.7039e+00 (3.7039e+00)\tAcc@1  23.00 ( 23.00)\tAcc@5  49.20 ( 49.20)\n",
      "Test: [ 50/100]\tTime  2.755 ( 1.815)\tLoss 5.1782e+00 (4.3818e+00)\tAcc@1   9.00 ( 16.51)\tAcc@5  22.40 ( 36.96)\n",
      " * Acc@1 16.572 Acc@5 36.536\n",
      "lr: [0.05]\n",
      "Epoch: [1][   0/1282]\tTime  4.455 ( 4.455)\tData  3.717 ( 3.717)\tLoss 3.4862e+00 (3.4862e+00)\tAcc@1  27.20 ( 27.20)\tAcc@5  53.40 ( 53.40)\n",
      "Epoch: [1][  50/1282]\tTime  2.350 ( 1.689)\tData  1.656 ( 0.995)\tLoss 3.4503e+00 (3.3783e+00)\tAcc@1  28.00 ( 29.13)\tAcc@5  53.40 ( 53.98)\n",
      "Epoch: [1][ 100/1282]\tTime  1.375 ( 1.658)\tData  0.697 ( 0.971)\tLoss 3.3375e+00 (3.3325e+00)\tAcc@1  31.80 ( 29.94)\tAcc@5  54.20 ( 55.01)\n",
      "Epoch: [1][ 150/1282]\tTime  0.776 ( 1.644)\tData  0.100 ( 0.958)\tLoss 3.2850e+00 (3.3007e+00)\tAcc@1  30.60 ( 30.29)\tAcc@5  56.00 ( 55.52)\n",
      "Epoch: [1][ 200/1282]\tTime  1.453 ( 1.644)\tData  0.748 ( 0.957)\tLoss 3.1744e+00 (3.2744e+00)\tAcc@1  32.20 ( 30.67)\tAcc@5  59.20 ( 55.95)\n",
      "Epoch: [1][ 250/1282]\tTime  2.077 ( 1.643)\tData  1.404 ( 0.957)\tLoss 3.1193e+00 (3.2547e+00)\tAcc@1  32.00 ( 30.93)\tAcc@5  59.60 ( 56.33)\n",
      "Epoch: [1][ 300/1282]\tTime  2.238 ( 1.643)\tData  1.565 ( 0.957)\tLoss 3.2643e+00 (3.2348e+00)\tAcc@1  32.20 ( 31.20)\tAcc@5  53.20 ( 56.66)\n",
      "Epoch: [1][ 350/1282]\tTime  2.590 ( 1.644)\tData  1.891 ( 0.958)\tLoss 3.1626e+00 (3.2191e+00)\tAcc@1  32.40 ( 31.47)\tAcc@5  56.80 ( 56.94)\n",
      "Epoch: [1][ 400/1282]\tTime  2.291 ( 1.645)\tData  1.610 ( 0.957)\tLoss 3.1319e+00 (3.2029e+00)\tAcc@1  33.60 ( 31.72)\tAcc@5  58.00 ( 57.27)\n",
      "Epoch: [1][ 450/1282]\tTime  2.399 ( 1.646)\tData  1.726 ( 0.958)\tLoss 3.0459e+00 (3.1882e+00)\tAcc@1  32.20 ( 32.02)\tAcc@5  60.40 ( 57.59)\n",
      "Epoch: [1][ 500/1282]\tTime  2.816 ( 1.647)\tData  2.080 ( 0.957)\tLoss 3.1761e+00 (3.1733e+00)\tAcc@1  33.80 ( 32.23)\tAcc@5  58.20 ( 57.86)\n",
      "Epoch: [1][ 550/1282]\tTime  2.525 ( 1.646)\tData  1.803 ( 0.956)\tLoss 3.1855e+00 (3.1591e+00)\tAcc@1  33.20 ( 32.46)\tAcc@5  58.40 ( 58.08)\n",
      "Epoch: [1][ 600/1282]\tTime  2.476 ( 1.645)\tData  1.766 ( 0.955)\tLoss 3.1806e+00 (3.1455e+00)\tAcc@1  32.40 ( 32.66)\tAcc@5  55.60 ( 58.33)\n",
      "Epoch: [1][ 650/1282]\tTime  2.437 ( 1.646)\tData  1.766 ( 0.955)\tLoss 2.8197e+00 (3.1311e+00)\tAcc@1  39.20 ( 32.90)\tAcc@5  63.20 ( 58.59)\n",
      "Epoch: [1][ 700/1282]\tTime  2.399 ( 1.645)\tData  1.723 ( 0.954)\tLoss 2.9034e+00 (3.1158e+00)\tAcc@1  35.80 ( 33.10)\tAcc@5  62.40 ( 58.87)\n",
      "Epoch: [1][ 750/1282]\tTime  2.548 ( 1.646)\tData  1.841 ( 0.955)\tLoss 3.1657e+00 (3.1048e+00)\tAcc@1  31.20 ( 33.26)\tAcc@5  57.60 ( 59.06)\n",
      "Epoch: [1][ 800/1282]\tTime  1.853 ( 1.644)\tData  1.173 ( 0.953)\tLoss 2.8950e+00 (3.0917e+00)\tAcc@1  35.40 ( 33.48)\tAcc@5  59.80 ( 59.29)\n",
      "Epoch: [1][ 850/1282]\tTime  2.018 ( 1.644)\tData  1.342 ( 0.953)\tLoss 2.7583e+00 (3.0773e+00)\tAcc@1  39.00 ( 33.71)\tAcc@5  65.60 ( 59.56)\n",
      "Epoch: [1][ 900/1282]\tTime  2.258 ( 1.643)\tData  1.550 ( 0.953)\tLoss 2.8246e+00 (3.0645e+00)\tAcc@1  35.40 ( 33.91)\tAcc@5  63.00 ( 59.78)\n",
      "Epoch: [1][ 950/1282]\tTime  2.528 ( 1.643)\tData  1.810 ( 0.953)\tLoss 2.6805e+00 (3.0518e+00)\tAcc@1  40.40 ( 34.12)\tAcc@5  66.20 ( 60.01)\n",
      "Epoch: [1][1000/1282]\tTime  2.382 ( 1.643)\tData  1.697 ( 0.953)\tLoss 2.8592e+00 (3.0409e+00)\tAcc@1  37.00 ( 34.31)\tAcc@5  66.40 ( 60.21)\n",
      "Epoch: [1][1050/1282]\tTime  2.595 ( 1.644)\tData  1.867 ( 0.953)\tLoss 2.9498e+00 (3.0301e+00)\tAcc@1  36.40 ( 34.49)\tAcc@5  63.60 ( 60.41)\n",
      "Epoch: [1][1100/1282]\tTime  2.087 ( 1.643)\tData  1.409 ( 0.952)\tLoss 2.7259e+00 (3.0188e+00)\tAcc@1  39.80 ( 34.67)\tAcc@5  65.60 ( 60.62)\n",
      "Epoch: [1][1150/1282]\tTime  1.922 ( 1.643)\tData  1.214 ( 0.952)\tLoss 2.7085e+00 (3.0068e+00)\tAcc@1  41.00 ( 34.87)\tAcc@5  65.60 ( 60.82)\n",
      "Epoch: [1][1200/1282]\tTime  0.683 ( 1.643)\tData  0.002 ( 0.952)\tLoss 2.5941e+00 (2.9938e+00)\tAcc@1  42.20 ( 35.09)\tAcc@5  69.00 ( 61.05)\n",
      "Epoch: [1][1250/1282]\tTime  0.691 ( 1.642)\tData  0.003 ( 0.951)\tLoss 2.7559e+00 (2.9827e+00)\tAcc@1  39.60 ( 35.28)\tAcc@5  66.20 ( 61.24)\n",
      "Test: [  0/100]\tTime  4.683 ( 4.683)\tLoss 2.2846e+00 (2.2846e+00)\tAcc@1  46.40 ( 46.40)\tAcc@5  75.00 ( 75.00)\n",
      "Test: [ 50/100]\tTime  2.978 ( 1.802)\tLoss 4.1001e+00 (2.9595e+00)\tAcc@1  18.60 ( 34.49)\tAcc@5  41.20 ( 61.79)\n",
      " * Acc@1 32.210 Acc@5 58.152\n",
      "lr: [0.0]\n",
      "CPU times: user 44min 15s, sys: 16min 13s, total: 1h 28s\n",
      "Wall time: 1h 16min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# start = time.time()\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})\n",
    "    \n",
    "# print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adc68068",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/data/runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
