{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# find_lr function\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DDP\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9dde",
   "metadata": {},
   "source": [
    "### Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39e242",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2296e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95f389",
   "metadata": {},
   "source": [
    "### Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f55eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.5-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 7.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 110.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 11.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 116.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.0)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 4.1 MB/s s eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Collecting termcolor<2.0.0,>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Building wheels for collected packages: promise, subprocess32, termcolor, pathtools\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=f72c29e4ee40f002945e3b554e81b091c3d29aec87ff86f59b80bdb82a10224b\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=994759c3de4c9d4ea4b655bea8c0723931bbb1a8aaddfaa8bff89a0dee919f8b\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/69/d1/50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=e2445abfdb7d48ec6bbdd061532f4cabb638967559b886b8b8e3616703d548bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=cd8a835c7a5116d2fa6dcff0bb27bc4baef8c9aa8268db126ea27e51eb6006ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built promise subprocess32 termcolor pathtools\n",
      "Installing collected packages: smmap, termcolor, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 termcolor-1.1.0 wandb-0.12.5 yaspin-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb72e29",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d1a0c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073b7b81",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "400ade2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint.pth.tar  model_best.pth.tar\ttrain  val  wandb  worker.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e18ae51",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "# ARCH = 'resnet152'\n",
    "EPOCHS = 2 #200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=500 #128\n",
    "VAL_BATCH=500 #128\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/hw9/train\"\n",
    "VALDIR=\"/data/hw9/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0efdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubyhan\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rubyhan/hw9_worker/runs/1ny40qwi\" target=\"_blank\">whole-disco-8</a></strong> to <a href=\"https://wandb.ai/rubyhan/hw9_worker\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rubyhan/hw9_worker/runs/1ny40qwi?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f2140e27e20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hw9_worker', \n",
    "           entity='rubyhan', \n",
    "           config = {\n",
    "               \"learning_rate\": LR,\n",
    "               \"epochs\": EPOCHS,\n",
    "               \"batch_size\": TRAIN_BATCH,\n",
    "               \"momentum\": MOMENTUM, \n",
    "               \"weight_decay\": WEIGHT_DECAY,\n",
    "               \"architecture\": ARCH\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf7c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "URL = 'tcp://172.31.26.78:1234'\n",
    "RANK = 1\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536a0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58857976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88d42a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "        # WITH AMP\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step += 1\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, \"acc1/train\": top1.avg, \"acc5/train\": top5.avg})\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa7d9fd",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5f0ab4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce30c86a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7504ce7a",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d659923",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f74f06e1",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c005e2dd",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, \n",
    "                                 std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d54592",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94059b7f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "788c0401",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63dc579e",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edf9cf5d",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "319e2d99",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "\n",
    "# Set model on BOTH GPUs\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8dc59b5",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3999d84a",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fae338b",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34dbcdb1",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5275a69",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "854ca1ad",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abfa5fb6",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07a0bdf4",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "192ae835",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#         val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1502c5db",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fdaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    meter_losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, meter_losses, top1, top5])\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        batch_num += 1\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        meter_losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return log_lrs, losses\n",
    "\n",
    "# logs,losses = find_lr()\n",
    "# plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 19.835 (19.835)\tData  4.067 ( 4.067)\tLoss 7.0188e+00 (7.0188e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.80 (  0.80)\n",
      "Epoch: [0][  50/1282]\tTime  1.421 ( 1.943)\tData  0.752 ( 0.963)\tLoss 6.6618e+00 (6.8381e+00)\tAcc@1   0.40 (  0.50)\tAcc@5   2.00 (  1.63)\n",
      "Epoch: [0][ 100/1282]\tTime  1.686 ( 1.812)\tData  1.001 ( 0.979)\tLoss 6.1125e+00 (6.6158e+00)\tAcc@1   2.20 (  0.90)\tAcc@5   8.40 (  3.13)\n",
      "Epoch: [0][ 150/1282]\tTime  0.858 ( 1.766)\tData  0.158 ( 0.979)\tLoss 5.8953e+00 (6.4179e+00)\tAcc@1   3.20 (  1.34)\tAcc@5  11.60 (  4.77)\n",
      "Epoch: [0][ 200/1282]\tTime  0.708 ( 1.753)\tData  0.002 ( 0.982)\tLoss 5.7518e+00 (6.2557e+00)\tAcc@1   3.80 (  1.88)\tAcc@5   9.80 (  6.28)\n",
      "Epoch: [0][ 250/1282]\tTime  0.714 ( 1.740)\tData  0.002 ( 0.978)\tLoss 5.5678e+00 (6.1138e+00)\tAcc@1   6.20 (  2.44)\tAcc@5  14.40 (  7.86)\n",
      "Epoch: [0][ 300/1282]\tTime  0.720 ( 1.736)\tData  0.002 ( 0.978)\tLoss 5.1852e+00 (5.9842e+00)\tAcc@1   8.40 (  3.02)\tAcc@5  19.20 (  9.46)\n",
      "Epoch: [0][ 350/1282]\tTime  0.723 ( 1.730)\tData  0.003 ( 0.976)\tLoss 5.2212e+00 (5.8659e+00)\tAcc@1   7.20 (  3.63)\tAcc@5  20.40 ( 11.01)\n",
      "Epoch: [0][ 400/1282]\tTime  0.718 ( 1.726)\tData  0.002 ( 0.973)\tLoss 4.8911e+00 (5.7615e+00)\tAcc@1   8.60 (  4.21)\tAcc@5  24.00 ( 12.45)\n",
      "Epoch: [0][ 450/1282]\tTime  0.732 ( 1.721)\tData  0.002 ( 0.970)\tLoss 4.6084e+00 (5.6661e+00)\tAcc@1  11.20 (  4.80)\tAcc@5  25.40 ( 13.84)\n",
      "Epoch: [0][ 500/1282]\tTime  0.818 ( 1.720)\tData  0.002 ( 0.971)\tLoss 4.7853e+00 (5.5751e+00)\tAcc@1  13.60 (  5.42)\tAcc@5  27.20 ( 15.17)\n",
      "Epoch: [0][ 550/1282]\tTime  0.727 ( 1.722)\tData  0.002 ( 0.972)\tLoss 4.5048e+00 (5.4917e+00)\tAcc@1  12.80 (  6.00)\tAcc@5  31.60 ( 16.42)\n",
      "Epoch: [0][ 600/1282]\tTime  0.744 ( 1.723)\tData  0.002 ( 0.974)\tLoss 4.7178e+00 (5.4135e+00)\tAcc@1  10.00 (  6.60)\tAcc@5  27.80 ( 17.64)\n",
      "Epoch: [0][ 650/1282]\tTime  0.718 ( 1.718)\tData  0.002 ( 0.970)\tLoss 4.2576e+00 (5.3387e+00)\tAcc@1  17.80 (  7.19)\tAcc@5  35.20 ( 18.85)\n",
      "Epoch: [0][ 700/1282]\tTime  0.728 ( 1.713)\tData  0.002 ( 0.967)\tLoss 4.4018e+00 (5.2673e+00)\tAcc@1  11.80 (  7.77)\tAcc@5  32.80 ( 20.02)\n",
      "Epoch: [0][ 750/1282]\tTime  0.723 ( 1.710)\tData  0.002 ( 0.965)\tLoss 4.2660e+00 (5.1990e+00)\tAcc@1  14.00 (  8.35)\tAcc@5  35.80 ( 21.19)\n",
      "Epoch: [0][ 800/1282]\tTime  0.724 ( 1.709)\tData  0.002 ( 0.964)\tLoss 4.0315e+00 (5.1333e+00)\tAcc@1  18.60 (  8.93)\tAcc@5  39.20 ( 22.32)\n",
      "Epoch: [0][ 850/1282]\tTime  0.956 ( 1.707)\tData  0.242 ( 0.964)\tLoss 3.7743e+00 (5.0704e+00)\tAcc@1  22.40 (  9.53)\tAcc@5  45.00 ( 23.41)\n",
      "Epoch: [0][ 900/1282]\tTime  0.710 ( 1.705)\tData  0.003 ( 0.963)\tLoss 3.9462e+00 (5.0113e+00)\tAcc@1  20.00 ( 10.08)\tAcc@5  44.60 ( 24.42)\n",
      "Epoch: [0][ 950/1282]\tTime  0.730 ( 1.706)\tData  0.003 ( 0.964)\tLoss 3.9998e+00 (4.9535e+00)\tAcc@1  18.60 ( 10.65)\tAcc@5  42.40 ( 25.43)\n",
      "Epoch: [0][1000/1282]\tTime  0.719 ( 1.704)\tData  0.002 ( 0.963)\tLoss 3.9419e+00 (4.8982e+00)\tAcc@1  22.20 ( 11.22)\tAcc@5  43.80 ( 26.41)\n",
      "Epoch: [0][1050/1282]\tTime  0.725 ( 1.702)\tData  0.002 ( 0.961)\tLoss 3.5451e+00 (4.8449e+00)\tAcc@1  25.40 ( 11.76)\tAcc@5  53.40 ( 27.36)\n",
      "Epoch: [0][1100/1282]\tTime  0.731 ( 1.702)\tData  0.002 ( 0.960)\tLoss 3.7289e+00 (4.7937e+00)\tAcc@1  24.20 ( 12.30)\tAcc@5  48.80 ( 28.28)\n",
      "Epoch: [0][1150/1282]\tTime  0.711 ( 1.701)\tData  0.002 ( 0.960)\tLoss 3.6598e+00 (4.7447e+00)\tAcc@1  24.60 ( 12.83)\tAcc@5  48.20 ( 29.14)\n",
      "Epoch: [0][1200/1282]\tTime  0.728 ( 1.700)\tData  0.002 ( 0.960)\tLoss 3.5357e+00 (4.6971e+00)\tAcc@1  25.80 ( 13.35)\tAcc@5  51.20 ( 30.00)\n",
      "Epoch: [0][1250/1282]\tTime  0.720 ( 1.699)\tData  0.002 ( 0.958)\tLoss 3.3682e+00 (4.6503e+00)\tAcc@1  28.80 ( 13.85)\tAcc@5  53.60 ( 30.84)\n",
      "Test: [ 0/50]\tTime  8.394 ( 8.394)\tLoss 4.0346e+00 (4.0346e+00)\tAcc@1  20.40 ( 20.40)\tAcc@5  40.80 ( 40.80)\n",
      " * Acc@1 21.056 Acc@5 44.164\n",
      "lr: [0.05]\n",
      "Epoch: [1][   0/1282]\tTime  4.541 ( 4.541)\tData  3.777 ( 3.777)\tLoss 3.5166e+00 (3.5166e+00)\tAcc@1  26.80 ( 26.80)\tAcc@5  50.60 ( 50.60)\n",
      "Epoch: [1][  50/1282]\tTime  2.704 ( 1.709)\tData  1.933 ( 0.955)\tLoss 3.3792e+00 (3.3204e+00)\tAcc@1  29.20 ( 29.95)\tAcc@5  55.00 ( 54.80)\n",
      "Epoch: [1][ 100/1282]\tTime  2.613 ( 1.691)\tData  1.860 ( 0.926)\tLoss 2.9488e+00 (3.2811e+00)\tAcc@1  34.00 ( 30.54)\tAcc@5  63.60 ( 55.66)\n",
      "Epoch: [1][ 150/1282]\tTime  2.499 ( 1.677)\tData  1.738 ( 0.905)\tLoss 3.2526e+00 (3.2512e+00)\tAcc@1  30.80 ( 30.86)\tAcc@5  57.00 ( 56.32)\n",
      "Epoch: [1][ 200/1282]\tTime  2.372 ( 1.668)\tData  1.657 ( 0.835)\tLoss 3.2826e+00 (3.2370e+00)\tAcc@1  30.20 ( 31.07)\tAcc@5  57.40 ( 56.57)\n",
      "Epoch: [1][ 250/1282]\tTime  2.635 ( 1.663)\tData  1.884 ( 0.846)\tLoss 3.2558e+00 (3.2207e+00)\tAcc@1  29.40 ( 31.44)\tAcc@5  58.00 ( 56.86)\n",
      "Epoch: [1][ 300/1282]\tTime  1.907 ( 1.658)\tData  1.190 ( 0.856)\tLoss 3.1223e+00 (3.2015e+00)\tAcc@1  34.00 ( 31.78)\tAcc@5  57.40 ( 57.21)\n",
      "Epoch: [1][ 350/1282]\tTime  0.806 ( 1.654)\tData  0.093 ( 0.863)\tLoss 3.1437e+00 (3.1846e+00)\tAcc@1  33.00 ( 32.05)\tAcc@5  60.40 ( 57.51)\n",
      "Epoch: [1][ 400/1282]\tTime  0.820 ( 1.653)\tData  0.093 ( 0.865)\tLoss 2.9213e+00 (3.1688e+00)\tAcc@1  36.40 ( 32.25)\tAcc@5  61.40 ( 57.81)\n",
      "Epoch: [1][ 450/1282]\tTime  0.815 ( 1.655)\tData  0.002 ( 0.870)\tLoss 2.8608e+00 (3.1556e+00)\tAcc@1  34.20 ( 32.48)\tAcc@5  64.60 ( 58.05)\n",
      "Epoch: [1][ 500/1282]\tTime  1.327 ( 1.657)\tData  0.002 ( 0.871)\tLoss 3.0425e+00 (3.1416e+00)\tAcc@1  35.00 ( 32.69)\tAcc@5  60.60 ( 58.30)\n",
      "Epoch: [1][ 550/1282]\tTime  0.861 ( 1.659)\tData  0.002 ( 0.862)\tLoss 2.9033e+00 (3.1290e+00)\tAcc@1  38.40 ( 32.88)\tAcc@5  62.00 ( 58.53)\n",
      "Epoch: [1][ 600/1282]\tTime  0.819 ( 1.661)\tData  0.003 ( 0.865)\tLoss 3.2042e+00 (3.1170e+00)\tAcc@1  31.40 ( 33.05)\tAcc@5  56.60 ( 58.73)\n",
      "Epoch: [1][ 650/1282]\tTime  0.860 ( 1.658)\tData  0.002 ( 0.865)\tLoss 2.8999e+00 (3.1040e+00)\tAcc@1  36.80 ( 33.27)\tAcc@5  63.00 ( 58.96)\n",
      "Epoch: [1][ 700/1282]\tTime  0.809 ( 1.657)\tData  0.002 ( 0.863)\tLoss 2.9610e+00 (3.0920e+00)\tAcc@1  34.20 ( 33.49)\tAcc@5  59.60 ( 59.18)\n",
      "Epoch: [1][ 750/1282]\tTime  1.002 ( 1.656)\tData  0.002 ( 0.862)\tLoss 2.9430e+00 (3.0793e+00)\tAcc@1  34.60 ( 33.70)\tAcc@5  59.60 ( 59.41)\n",
      "Epoch: [1][ 800/1282]\tTime  0.812 ( 1.655)\tData  0.003 ( 0.862)\tLoss 2.7522e+00 (3.0647e+00)\tAcc@1  37.20 ( 33.93)\tAcc@5  65.40 ( 59.68)\n",
      "Epoch: [1][ 850/1282]\tTime  0.820 ( 1.654)\tData  0.095 ( 0.864)\tLoss 2.6484e+00 (3.0529e+00)\tAcc@1  44.60 ( 34.11)\tAcc@5  69.20 ( 59.91)\n",
      "Epoch: [1][ 900/1282]\tTime  0.730 ( 1.655)\tData  0.002 ( 0.868)\tLoss 2.8623e+00 (3.0417e+00)\tAcc@1  38.20 ( 34.28)\tAcc@5  61.00 ( 60.09)\n",
      "Epoch: [1][ 950/1282]\tTime  0.731 ( 1.654)\tData  0.002 ( 0.869)\tLoss 2.8848e+00 (3.0300e+00)\tAcc@1  35.80 ( 34.48)\tAcc@5  63.00 ( 60.32)\n",
      "Epoch: [1][1000/1282]\tTime  0.722 ( 1.654)\tData  0.002 ( 0.872)\tLoss 2.8460e+00 (3.0174e+00)\tAcc@1  38.60 ( 34.70)\tAcc@5  63.20 ( 60.55)\n",
      "Epoch: [1][1050/1282]\tTime  0.729 ( 1.653)\tData  0.002 ( 0.874)\tLoss 2.6892e+00 (3.0062e+00)\tAcc@1  43.60 ( 34.89)\tAcc@5  66.60 ( 60.75)\n",
      "Epoch: [1][1100/1282]\tTime  0.726 ( 1.654)\tData  0.002 ( 0.877)\tLoss 2.7186e+00 (2.9947e+00)\tAcc@1  37.80 ( 35.08)\tAcc@5  66.20 ( 60.97)\n",
      "Epoch: [1][1150/1282]\tTime  0.726 ( 1.654)\tData  0.002 ( 0.878)\tLoss 2.7699e+00 (2.9841e+00)\tAcc@1  38.80 ( 35.26)\tAcc@5  64.80 ( 61.16)\n",
      "Epoch: [1][1200/1282]\tTime  0.818 ( 1.653)\tData  0.002 ( 0.877)\tLoss 2.7272e+00 (2.9737e+00)\tAcc@1  40.60 ( 35.44)\tAcc@5  66.60 ( 61.34)\n",
      "Epoch: [1][1250/1282]\tTime  0.728 ( 1.653)\tData  0.002 ( 0.877)\tLoss 2.5798e+00 (2.9619e+00)\tAcc@1  42.20 ( 35.62)\tAcc@5  68.00 ( 61.56)\n",
      "Test: [ 0/50]\tTime  4.721 ( 4.721)\tLoss 3.2783e+00 (3.2783e+00)\tAcc@1  31.20 ( 31.20)\tAcc@5  54.80 ( 54.80)\n",
      " * Acc@1 32.672 Acc@5 58.272\n",
      "lr: [0.0]\n",
      "CPU times: user 46min 3s, sys: 17min 17s, total: 1h 3min 21s\n",
      "Wall time: 1h 14min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# start = time.time()\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})\n",
    "    \n",
    "# print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adc68068",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/data/runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
