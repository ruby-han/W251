{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "# find_lr function\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# DDP\n",
    "import torch.distributed as dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9dde",
   "metadata": {},
   "source": [
    "### Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39e242",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2296e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95f389",
   "metadata": {},
   "source": [
    "### Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f55eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.5-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 104.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 109.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 3.2 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Collecting termcolor<2.0.0,>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Building wheels for collected packages: promise, subprocess32, termcolor, pathtools\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=03eb55b358405491e488426e7725f896f6aa6291e8018386fb32ffb354bb5a37\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=6862d354320f93059f44bfe1b9457509f2784a6103596aab4a148bbaa13bffea\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/69/d1/50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=b4663b900e61cef8ce6855af8d7d6e4a3d1bfdf8ce4abbb8a7e651b636c3330c\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=502db7c19088577153161a4557ed9592cc903486de12c60887fc129fccf951b7\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built promise subprocess32 termcolor pathtools\n",
      "Installing collected packages: smmap, termcolor, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 termcolor-1.1.0 wandb-0.12.5 yaspin-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb72e29",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d1a0c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "073b7b81",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "400ade2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint.pth.tar  model_best.pth.tar\ttrain  val  wandb  worker.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e18ae51",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "# ARCH = 'resnet152'\n",
    "EPOCHS = 2 #200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=500 #128\n",
    "VAL_BATCH=500 #128\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/hw9/train\"\n",
    "VALDIR=\"/data/hw9/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c0efdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubyhan\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rubyhan/hw9_worker/runs/zj8rzz6g\" target=\"_blank\">upbeat-water-7</a></strong> to <a href=\"https://wandb.ai/rubyhan/hw9_worker\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rubyhan/hw9_worker/runs/zj8rzz6g?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f839d31b580>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hw9_worker', \n",
    "           entity='rubyhan', \n",
    "           config = {\n",
    "               \"learning_rate\": LR,\n",
    "               \"epochs\": EPOCHS,\n",
    "               \"batch_size\": TRAIN_BATCH,\n",
    "               \"momentum\": MOMENTUM, \n",
    "               \"weight_decay\": WEIGHT_DECAY,\n",
    "               \"architecture\": ARCH\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf7c6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDP\n",
    "WORLD_SIZE = 2\n",
    "BACKEND = 'nccl'\n",
    "URL = 'tcp://172.31.26.78:1234'\n",
    "RANK = 1\n",
    "\n",
    "dist.init_process_group(backend = BACKEND, init_method= URL,\n",
    "                                world_size= WORLD_SIZE, rank=RANK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536a0754",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33b36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58857976",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "88d42a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "        # WITH AMP\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step += 1\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, \"acc1/train\": top1.avg, \"acc5/train\": top5.avg})\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afa7d9fd",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c5f0ab4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce30c86a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7504ce7a",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d659923",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f74f06e1",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c005e2dd",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, \n",
    "                                 std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29d54592",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94059b7f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "788c0401",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63dc579e",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edf9cf5d",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "319e2d99",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [],
   "source": [
    "model.cuda(GPU)\n",
    "\n",
    "# Set model on BOTH GPUs\n",
    "model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[GPU])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8dc59b5",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3999d84a",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fae338b",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34dbcdb1",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5275a69",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "854ca1ad",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abfa5fb6",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "07a0bdf4",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "# train_loader = torch.utils.data.DataLoader(\n",
    "#         train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "192ae835",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "# val_loader = torch.utils.data.DataLoader(\n",
    "#         val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "#         num_workers=WORKERS, pin_memory=True, sampler=None)\n",
    "\n",
    "# adding DDSampler to loader\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=torch.utils.data.distributed.DistributedSampler(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1502c5db",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fdaa56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    meter_losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, meter_losses, top1, top5])\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        batch_num += 1\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        meter_losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return log_lrs, losses\n",
    "\n",
    "# logs,losses = find_lr()\n",
    "# plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/1282]\tTime 19.578 (19.578)\tData  4.175 ( 4.175)\tLoss 7.0188e+00 (7.0188e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.80 (  0.80)\n",
      "Epoch: [0][  50/1282]\tTime  0.665 ( 1.928)\tData  0.002 ( 0.945)\tLoss 6.6397e+00 (6.8345e+00)\tAcc@1   0.40 (  0.49)\tAcc@5   2.40 (  1.81)\n",
      "Epoch: [0][ 100/1282]\tTime  1.412 ( 1.812)\tData  0.751 ( 0.980)\tLoss 6.1260e+00 (6.6114e+00)\tAcc@1   2.20 (  0.87)\tAcc@5   7.60 (  3.22)\n",
      "Epoch: [0][ 150/1282]\tTime  0.756 ( 1.771)\tData  0.091 ( 0.993)\tLoss 5.8674e+00 (6.4193e+00)\tAcc@1   4.60 (  1.33)\tAcc@5  11.00 (  4.77)\n",
      "Epoch: [0][ 200/1282]\tTime  0.715 ( 1.750)\tData  0.002 ( 0.990)\tLoss 5.7007e+00 (6.2557e+00)\tAcc@1   4.80 (  1.87)\tAcc@5  12.20 (  6.32)\n",
      "Epoch: [0][ 250/1282]\tTime  0.691 ( 1.735)\tData  0.003 ( 0.985)\tLoss 5.5211e+00 (6.1116e+00)\tAcc@1   4.60 (  2.47)\tAcc@5  14.20 (  7.93)\n",
      "Epoch: [0][ 300/1282]\tTime  0.728 ( 1.727)\tData  0.003 ( 0.984)\tLoss 5.1714e+00 (5.9827e+00)\tAcc@1   9.00 (  3.09)\tAcc@5  21.40 (  9.54)\n",
      "Epoch: [0][ 350/1282]\tTime  0.701 ( 1.722)\tData  0.003 ( 0.983)\tLoss 5.3423e+00 (5.8666e+00)\tAcc@1   8.40 (  3.68)\tAcc@5  17.60 ( 11.04)\n",
      "Epoch: [0][ 400/1282]\tTime  0.696 ( 1.716)\tData  0.003 ( 0.980)\tLoss 4.9455e+00 (5.7672e+00)\tAcc@1   9.00 (  4.22)\tAcc@5  23.00 ( 12.41)\n",
      "Epoch: [0][ 450/1282]\tTime  0.695 ( 1.713)\tData  0.002 ( 0.980)\tLoss 4.5997e+00 (5.6737e+00)\tAcc@1  11.60 (  4.83)\tAcc@5  27.20 ( 13.77)\n",
      "Epoch: [0][ 500/1282]\tTime  0.696 ( 1.713)\tData  0.002 ( 0.982)\tLoss 4.8187e+00 (5.5855e+00)\tAcc@1  13.60 (  5.41)\tAcc@5  27.00 ( 15.04)\n",
      "Epoch: [0][ 550/1282]\tTime  0.727 ( 1.715)\tData  0.002 ( 0.985)\tLoss 4.5735e+00 (5.5043e+00)\tAcc@1  13.80 (  5.98)\tAcc@5  33.00 ( 16.25)\n",
      "Epoch: [0][ 600/1282]\tTime  0.697 ( 1.712)\tData  0.002 ( 0.983)\tLoss 4.6969e+00 (5.4270e+00)\tAcc@1  11.00 (  6.57)\tAcc@5  28.40 ( 17.47)\n",
      "Epoch: [0][ 650/1282]\tTime  0.699 ( 1.709)\tData  0.002 ( 0.981)\tLoss 4.3071e+00 (5.3532e+00)\tAcc@1  15.60 (  7.16)\tAcc@5  36.00 ( 18.67)\n",
      "Epoch: [0][ 700/1282]\tTime  0.721 ( 1.706)\tData  0.002 ( 0.979)\tLoss 4.3693e+00 (5.2826e+00)\tAcc@1  14.40 (  7.72)\tAcc@5  33.00 ( 19.81)\n",
      "Epoch: [0][ 750/1282]\tTime  0.702 ( 1.704)\tData  0.002 ( 0.979)\tLoss 4.2580e+00 (5.2147e+00)\tAcc@1  14.80 (  8.30)\tAcc@5  34.20 ( 20.93)\n",
      "Epoch: [0][ 800/1282]\tTime  0.698 ( 1.703)\tData  0.002 ( 0.978)\tLoss 4.1025e+00 (5.1502e+00)\tAcc@1  17.60 (  8.85)\tAcc@5  39.00 ( 22.01)\n",
      "Epoch: [0][ 850/1282]\tTime  0.694 ( 1.702)\tData  0.002 ( 0.978)\tLoss 3.8472e+00 (5.0885e+00)\tAcc@1  20.20 (  9.42)\tAcc@5  43.60 ( 23.05)\n",
      "Epoch: [0][ 900/1282]\tTime  0.694 ( 1.701)\tData  0.003 ( 0.978)\tLoss 3.9664e+00 (5.0294e+00)\tAcc@1  20.60 (  9.95)\tAcc@5  42.20 ( 24.05)\n",
      "Epoch: [0][ 950/1282]\tTime  0.696 ( 1.700)\tData  0.002 ( 0.977)\tLoss 4.0763e+00 (4.9728e+00)\tAcc@1  16.20 ( 10.51)\tAcc@5  41.60 ( 25.05)\n",
      "Epoch: [0][1000/1282]\tTime  0.696 ( 1.698)\tData  0.002 ( 0.977)\tLoss 3.9667e+00 (4.9170e+00)\tAcc@1  21.60 ( 11.07)\tAcc@5  45.60 ( 26.04)\n",
      "Epoch: [0][1050/1282]\tTime  0.724 ( 1.698)\tData  0.003 ( 0.976)\tLoss 3.6267e+00 (4.8642e+00)\tAcc@1  26.80 ( 11.62)\tAcc@5  50.20 ( 26.98)\n",
      "Epoch: [0][1100/1282]\tTime  0.738 ( 1.698)\tData  0.002 ( 0.976)\tLoss 3.7386e+00 (4.8134e+00)\tAcc@1  22.80 ( 12.13)\tAcc@5  49.20 ( 27.89)\n",
      "Epoch: [0][1150/1282]\tTime  0.700 ( 1.696)\tData  0.002 ( 0.974)\tLoss 3.7296e+00 (4.7648e+00)\tAcc@1  23.40 ( 12.65)\tAcc@5  47.60 ( 28.77)\n",
      "Epoch: [0][1200/1282]\tTime  0.726 ( 1.695)\tData  0.002 ( 0.974)\tLoss 3.5569e+00 (4.7177e+00)\tAcc@1  25.80 ( 13.16)\tAcc@5  52.20 ( 29.62)\n",
      "Epoch: [0][1250/1282]\tTime  0.700 ( 1.694)\tData  0.002 ( 0.973)\tLoss 3.3395e+00 (4.6710e+00)\tAcc@1  27.20 ( 13.67)\tAcc@5  54.20 ( 30.47)\n",
      "Test: [ 0/50]\tTime  8.275 ( 8.275)\tLoss 4.4368e+00 (4.4368e+00)\tAcc@1  15.20 ( 15.20)\tAcc@5  34.20 ( 34.20)\n",
      " * Acc@1 16.448 Acc@5 36.420\n",
      "lr: [0.05]\n",
      "Epoch: [1][   0/1282]\tTime  4.825 ( 4.825)\tData  4.095 ( 4.095)\tLoss 3.5795e+00 (3.5795e+00)\tAcc@1  25.20 ( 25.20)\tAcc@5  52.00 ( 52.00)\n",
      "Epoch: [1][  50/1282]\tTime  2.813 ( 1.740)\tData  2.079 ( 1.021)\tLoss 3.4010e+00 (3.3414e+00)\tAcc@1  27.60 ( 29.95)\tAcc@5  56.80 ( 54.82)\n",
      "Epoch: [1][ 100/1282]\tTime  2.714 ( 1.701)\tData  1.966 ( 0.977)\tLoss 2.9314e+00 (3.3070e+00)\tAcc@1  37.00 ( 30.28)\tAcc@5  64.20 ( 55.42)\n",
      "Epoch: [1][ 150/1282]\tTime  2.439 ( 1.687)\tData  1.706 ( 0.955)\tLoss 3.2672e+00 (3.2768e+00)\tAcc@1  31.20 ( 30.54)\tAcc@5  55.80 ( 56.00)\n",
      "Epoch: [1][ 200/1282]\tTime  1.123 ( 1.671)\tData  0.394 ( 0.939)\tLoss 3.2899e+00 (3.2589e+00)\tAcc@1  31.40 ( 30.86)\tAcc@5  55.60 ( 56.35)\n",
      "Epoch: [1][ 250/1282]\tTime  0.831 ( 1.664)\tData  0.102 ( 0.930)\tLoss 3.2615e+00 (3.2417e+00)\tAcc@1  32.00 ( 31.20)\tAcc@5  56.20 ( 56.65)\n",
      "Epoch: [1][ 300/1282]\tTime  0.829 ( 1.662)\tData  0.002 ( 0.921)\tLoss 3.0897e+00 (3.2225e+00)\tAcc@1  32.80 ( 31.46)\tAcc@5  57.20 ( 56.96)\n",
      "Epoch: [1][ 350/1282]\tTime  0.929 ( 1.658)\tData  0.002 ( 0.909)\tLoss 3.1607e+00 (3.2063e+00)\tAcc@1  34.20 ( 31.65)\tAcc@5  60.00 ( 57.25)\n",
      "Epoch: [1][ 400/1282]\tTime  0.834 ( 1.655)\tData  0.002 ( 0.898)\tLoss 2.9196e+00 (3.1901e+00)\tAcc@1  37.20 ( 31.85)\tAcc@5  60.00 ( 57.55)\n",
      "Epoch: [1][ 450/1282]\tTime  0.932 ( 1.656)\tData  0.002 ( 0.893)\tLoss 2.8379e+00 (3.1766e+00)\tAcc@1  35.00 ( 32.10)\tAcc@5  63.80 ( 57.79)\n",
      "Epoch: [1][ 500/1282]\tTime  1.123 ( 1.657)\tData  0.002 ( 0.887)\tLoss 3.0645e+00 (3.1626e+00)\tAcc@1  34.20 ( 32.31)\tAcc@5  60.20 ( 58.04)\n",
      "Epoch: [1][ 550/1282]\tTime  0.771 ( 1.660)\tData  0.002 ( 0.883)\tLoss 2.8510e+00 (3.1496e+00)\tAcc@1  39.40 ( 32.53)\tAcc@5  64.20 ( 58.28)\n",
      "Epoch: [1][ 600/1282]\tTime  0.756 ( 1.661)\tData  0.002 ( 0.884)\tLoss 3.2563e+00 (3.1379e+00)\tAcc@1  31.80 ( 32.72)\tAcc@5  56.60 ( 58.47)\n",
      "Epoch: [1][ 650/1282]\tTime  0.775 ( 1.662)\tData  0.002 ( 0.887)\tLoss 2.9068e+00 (3.1245e+00)\tAcc@1  37.20 ( 32.95)\tAcc@5  63.80 ( 58.69)\n",
      "Epoch: [1][ 700/1282]\tTime  0.703 ( 1.662)\tData  0.002 ( 0.888)\tLoss 2.9672e+00 (3.1117e+00)\tAcc@1  35.60 ( 33.18)\tAcc@5  58.80 ( 58.91)\n",
      "Epoch: [1][ 750/1282]\tTime  0.733 ( 1.661)\tData  0.002 ( 0.891)\tLoss 2.9456e+00 (3.0981e+00)\tAcc@1  34.60 ( 33.39)\tAcc@5  60.60 ( 59.15)\n",
      "Epoch: [1][ 800/1282]\tTime  0.830 ( 1.661)\tData  0.095 ( 0.892)\tLoss 2.8384e+00 (3.0834e+00)\tAcc@1  38.80 ( 33.63)\tAcc@5  64.40 ( 59.42)\n",
      "Epoch: [1][ 850/1282]\tTime  0.832 ( 1.661)\tData  0.099 ( 0.893)\tLoss 2.7219e+00 (3.0706e+00)\tAcc@1  40.20 ( 33.83)\tAcc@5  66.60 ( 59.66)\n",
      "Epoch: [1][ 900/1282]\tTime  0.769 ( 1.662)\tData  0.002 ( 0.896)\tLoss 2.8650e+00 (3.0587e+00)\tAcc@1  39.80 ( 34.02)\tAcc@5  63.80 ( 59.86)\n",
      "Epoch: [1][ 950/1282]\tTime  0.776 ( 1.664)\tData  0.002 ( 0.898)\tLoss 2.9088e+00 (3.0463e+00)\tAcc@1  37.40 ( 34.23)\tAcc@5  62.60 ( 60.08)\n",
      "Epoch: [1][1000/1282]\tTime  0.718 ( 1.665)\tData  0.002 ( 0.900)\tLoss 2.8392e+00 (3.0337e+00)\tAcc@1  36.00 ( 34.45)\tAcc@5  64.60 ( 60.30)\n",
      "Epoch: [1][1050/1282]\tTime  0.700 ( 1.665)\tData  0.002 ( 0.902)\tLoss 2.6728e+00 (3.0221e+00)\tAcc@1  41.20 ( 34.63)\tAcc@5  68.60 ( 60.52)\n",
      "Epoch: [1][1100/1282]\tTime  0.715 ( 1.667)\tData  0.002 ( 0.905)\tLoss 2.7175e+00 (3.0105e+00)\tAcc@1  38.80 ( 34.83)\tAcc@5  67.40 ( 60.74)\n",
      "Epoch: [1][1150/1282]\tTime  0.744 ( 1.667)\tData  0.003 ( 0.906)\tLoss 2.7633e+00 (3.0000e+00)\tAcc@1  37.80 ( 35.00)\tAcc@5  65.60 ( 60.93)\n",
      "Epoch: [1][1200/1282]\tTime  0.757 ( 1.667)\tData  0.003 ( 0.907)\tLoss 2.7390e+00 (2.9894e+00)\tAcc@1  39.80 ( 35.16)\tAcc@5  68.20 ( 61.10)\n",
      "Epoch: [1][1250/1282]\tTime  0.772 ( 1.668)\tData  0.002 ( 0.907)\tLoss 2.6000e+00 (2.9774e+00)\tAcc@1  40.60 ( 35.36)\tAcc@5  68.40 ( 61.33)\n",
      "Test: [ 0/50]\tTime  4.762 ( 4.762)\tLoss 3.1831e+00 (3.1831e+00)\tAcc@1  32.60 ( 32.60)\tAcc@5  56.80 ( 56.80)\n",
      " * Acc@1 32.216 Acc@5 58.184\n",
      "lr: [0.0]\n",
      "CPU times: user 45min 29s, sys: 16min 18s, total: 1h 1min 47s\n",
      "Wall time: 1h 14min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# start = time.time()\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})\n",
    "    \n",
    "# print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "adc68068",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/data/runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
