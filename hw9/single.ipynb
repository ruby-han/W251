{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9dde",
   "metadata": {},
   "source": [
    "### Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39e242",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2296e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95f389",
   "metadata": {},
   "source": [
    "### Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f55eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Downloading wandb-0.12.5-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 6.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/lib/python3.8/site-packages (from wandb) (5.4.1)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: six>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (1.16.0)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (7.1.2)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.4.3-py2.py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 120.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (3.17.3)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "\u001b[K     |████████████████████████████████| 180 kB 123.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from wandb) (2.26.0)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 14.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 3.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from GitPython>=1.0.0->wandb) (3.10.0.0)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (3.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.0.0->wandb) (1.26.6)\n",
      "Collecting termcolor<2.0.0,>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Building wheels for collected packages: promise, subprocess32, termcolor, pathtools\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21502 sha256=b34ea424df633e397547537cee85c915abd8298e6a38dca6abafdd9c40eaee9c\n",
      "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=0428f0daeec663d02d0934d789a2101ed2f1cbced3f28ec38a9ba08094058787\n",
      "  Stored in directory: /root/.cache/pip/wheels/9f/69/d1/50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4847 sha256=97b076c33859689f52cb1237713bcc3c4d18dcbe7068562e2cf9fc501c7b88e8\n",
      "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=3a0dbcd467c8135038fa22adef4fe4a9ddf34c0e52772fdefab175d40edacb4c\n",
      "  Stored in directory: /root/.cache/pip/wheels/4c/8e/7e/72fbc243e1aeecae64a96875432e70d4e92f3d2d18123be004\n",
      "Successfully built promise subprocess32 termcolor pathtools\n",
      "Installing collected packages: smmap, termcolor, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, configparser, wandb\n",
      "Successfully installed GitPython-3.1.24 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 promise-2.3 sentry-sdk-1.4.3 shortuuid-1.0.1 smmap-5.0.0 subprocess32-3.5.4 termcolor-1.1.0 wandb-0.12.5 yaspin-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Paste an API key from your profile and hit enter: ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb72e29",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d1a0c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b270c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129b73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ea7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073b7b81",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e18ae51",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "# ARCH = 'resnet152'\n",
    "EPOCHS = 2 #200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=500 #128\n",
    "VAL_BATCH=500 #128\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/hw9/train\"\n",
    "VALDIR=\"/data/hw9/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0efdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubyhan\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rubyhan/hw9_single/runs/oyrh1ea5\" target=\"_blank\">autumn-resonance-11</a></strong> to <a href=\"https://wandb.ai/rubyhan/hw9_single\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rubyhan/hw9_single/runs/oyrh1ea5?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fa37e88fc70>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hw9_single', \n",
    "           entity='rubyhan', \n",
    "           config = {\n",
    "               \"learning_rate\": LR,\n",
    "               \"epochs\": EPOCHS,\n",
    "               \"batch_size\": TRAIN_BATCH,\n",
    "               \"momentum\": MOMENTUM, \n",
    "               \"weight_decay\": WEIGHT_DECAY,\n",
    "               \"architecture\": ARCH\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d42a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "        # WITH AMP\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step += 1\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, \"acc1/train\": top1.avg, \"acc5/train\": top5.avg})\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa7d9fd",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5f0ab4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce30c86a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7504ce7a",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d659923",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f74f06e1",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c005e2dd",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, \n",
    "                                 std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29d54592",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94059b7f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788c0401",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63dc579e",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edf9cf5d",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319e2d99",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8dc59b5",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3999d84a",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fae338b",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34dbcdb1",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5275a69",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "854ca1ad",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abfa5fb6",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07a0bdf4",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192ae835",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1502c5db",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e37e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    meter_losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, meter_losses, top1, top5])\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        batch_num += 1\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        meter_losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return log_lrs, losses\n",
    "\n",
    "# logs,losses = find_lr()\n",
    "# plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2563]\tTime 19.303 (19.303)\tData  3.999 ( 3.999)\tLoss 7.0159e+00 (7.0159e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  50/2563]\tTime  2.292 ( 1.909)\tData  1.650 ( 0.977)\tLoss 6.7518e+00 (6.9066e+00)\tAcc@1   0.40 (  0.40)\tAcc@5   2.00 (  1.55)\n",
      "Epoch: [0][ 100/2563]\tTime  1.795 ( 1.771)\tData  1.143 ( 0.981)\tLoss 6.4570e+00 (6.7316e+00)\tAcc@1   0.60 (  0.66)\tAcc@5   4.80 (  2.51)\n",
      "Epoch: [0][ 150/2563]\tTime  1.753 ( 1.730)\tData  1.099 ( 0.986)\tLoss 6.2233e+00 (6.5897e+00)\tAcc@1   0.60 (  0.94)\tAcc@5   4.00 (  3.39)\n",
      "Epoch: [0][ 200/2563]\tTime  0.724 ( 1.703)\tData  0.090 ( 0.984)\tLoss 5.9828e+00 (6.4707e+00)\tAcc@1   1.40 (  1.15)\tAcc@5   7.00 (  4.17)\n",
      "Epoch: [0][ 250/2563]\tTime  0.637 ( 1.692)\tData  0.002 ( 0.988)\tLoss 5.7823e+00 (6.3615e+00)\tAcc@1   2.60 (  1.47)\tAcc@5  11.40 (  5.13)\n",
      "Epoch: [0][ 300/2563]\tTime  0.734 ( 1.682)\tData  0.095 ( 0.985)\tLoss 5.7651e+00 (6.2702e+00)\tAcc@1   3.20 (  1.70)\tAcc@5  10.60 (  5.96)\n",
      "Epoch: [0][ 350/2563]\tTime  0.730 ( 1.670)\tData  0.092 ( 0.979)\tLoss 5.5692e+00 (6.1820e+00)\tAcc@1   5.20 (  1.99)\tAcc@5  13.40 (  6.87)\n",
      "Epoch: [0][ 400/2563]\tTime  0.726 ( 1.665)\tData  0.090 ( 0.978)\tLoss 5.4092e+00 (6.1002e+00)\tAcc@1   6.60 (  2.31)\tAcc@5  16.80 (  7.79)\n",
      "Epoch: [0][ 450/2563]\tTime  0.639 ( 1.659)\tData  0.002 ( 0.976)\tLoss 5.3126e+00 (6.0208e+00)\tAcc@1   5.40 (  2.66)\tAcc@5  20.00 (  8.73)\n",
      "Epoch: [0][ 500/2563]\tTime  0.640 ( 1.653)\tData  0.002 ( 0.973)\tLoss 5.2739e+00 (5.9489e+00)\tAcc@1   7.40 (  3.00)\tAcc@5  19.40 (  9.61)\n",
      "Epoch: [0][ 550/2563]\tTime  0.657 ( 1.649)\tData  0.002 ( 0.971)\tLoss 5.1315e+00 (5.8810e+00)\tAcc@1   7.40 (  3.34)\tAcc@5  23.00 ( 10.50)\n",
      "Epoch: [0][ 600/2563]\tTime  0.659 ( 1.646)\tData  0.002 ( 0.969)\tLoss 5.0268e+00 (5.8162e+00)\tAcc@1  10.00 (  3.67)\tAcc@5  25.20 ( 11.36)\n",
      "Epoch: [0][ 650/2563]\tTime  0.664 ( 1.646)\tData  0.002 ( 0.969)\tLoss 5.0004e+00 (5.7561e+00)\tAcc@1   9.00 (  4.00)\tAcc@5  21.80 ( 12.18)\n",
      "Epoch: [0][ 700/2563]\tTime  0.659 ( 1.643)\tData  0.002 ( 0.967)\tLoss 5.0089e+00 (5.6992e+00)\tAcc@1   8.60 (  4.33)\tAcc@5  22.80 ( 13.00)\n",
      "Epoch: [0][ 750/2563]\tTime  0.637 ( 1.641)\tData  0.002 ( 0.965)\tLoss 4.7861e+00 (5.6430e+00)\tAcc@1  10.80 (  4.68)\tAcc@5  25.60 ( 13.83)\n",
      "Epoch: [0][ 800/2563]\tTime  0.637 ( 1.641)\tData  0.002 ( 0.967)\tLoss 4.6403e+00 (5.5906e+00)\tAcc@1  12.40 (  5.02)\tAcc@5  27.40 ( 14.59)\n",
      "Epoch: [0][ 850/2563]\tTime  0.640 ( 1.639)\tData  0.002 ( 0.965)\tLoss 4.6093e+00 (5.5397e+00)\tAcc@1  11.60 (  5.38)\tAcc@5  28.80 ( 15.36)\n",
      "Epoch: [0][ 900/2563]\tTime  0.642 ( 1.638)\tData  0.002 ( 0.965)\tLoss 4.4954e+00 (5.4900e+00)\tAcc@1  14.00 (  5.73)\tAcc@5  32.80 ( 16.13)\n",
      "Epoch: [0][ 950/2563]\tTime  0.638 ( 1.636)\tData  0.002 ( 0.965)\tLoss 4.6809e+00 (5.4423e+00)\tAcc@1  10.40 (  6.09)\tAcc@5  26.20 ( 16.88)\n",
      "Epoch: [0][1000/2563]\tTime  0.638 ( 1.634)\tData  0.003 ( 0.964)\tLoss 4.5390e+00 (5.3964e+00)\tAcc@1  12.40 (  6.44)\tAcc@5  32.40 ( 17.63)\n",
      "Epoch: [0][1050/2563]\tTime  0.643 ( 1.635)\tData  0.002 ( 0.965)\tLoss 4.4964e+00 (5.3528e+00)\tAcc@1  12.40 (  6.79)\tAcc@5  30.40 ( 18.33)\n",
      "Epoch: [0][1100/2563]\tTime  0.641 ( 1.634)\tData  0.002 ( 0.965)\tLoss 4.3017e+00 (5.3092e+00)\tAcc@1  18.20 (  7.15)\tAcc@5  36.60 ( 19.05)\n",
      "Epoch: [0][1150/2563]\tTime  0.636 ( 1.633)\tData  0.002 ( 0.964)\tLoss 4.3787e+00 (5.2671e+00)\tAcc@1  15.00 (  7.48)\tAcc@5  34.00 ( 19.74)\n",
      "Epoch: [0][1200/2563]\tTime  0.638 ( 1.632)\tData  0.002 ( 0.964)\tLoss 4.2680e+00 (5.2257e+00)\tAcc@1  18.40 (  7.84)\tAcc@5  39.40 ( 20.44)\n",
      "Epoch: [0][1250/2563]\tTime  0.649 ( 1.630)\tData  0.002 ( 0.963)\tLoss 4.2515e+00 (5.1853e+00)\tAcc@1  17.00 (  8.19)\tAcc@5  36.20 ( 21.11)\n",
      "Epoch: [0][1300/2563]\tTime  0.976 ( 1.629)\tData  0.342 ( 0.963)\tLoss 4.1449e+00 (5.1466e+00)\tAcc@1  18.00 (  8.54)\tAcc@5  38.20 ( 21.76)\n",
      "Epoch: [0][1350/2563]\tTime  1.476 ( 1.630)\tData  0.841 ( 0.964)\tLoss 3.9905e+00 (5.1094e+00)\tAcc@1  20.40 (  8.87)\tAcc@5  40.60 ( 22.41)\n",
      "Epoch: [0][1400/2563]\tTime  2.657 ( 1.631)\tData  1.942 ( 0.966)\tLoss 3.9519e+00 (5.0715e+00)\tAcc@1  18.80 (  9.22)\tAcc@5  44.00 ( 23.06)\n",
      "Epoch: [0][1450/2563]\tTime  1.451 ( 1.630)\tData  0.807 ( 0.966)\tLoss 4.1199e+00 (5.0354e+00)\tAcc@1  19.00 (  9.57)\tAcc@5  40.00 ( 23.70)\n",
      "Epoch: [0][1500/2563]\tTime  0.651 ( 1.630)\tData  0.002 ( 0.967)\tLoss 3.9354e+00 (5.0004e+00)\tAcc@1  18.80 (  9.90)\tAcc@5  43.40 ( 24.31)\n",
      "Epoch: [0][1550/2563]\tTime  1.246 ( 1.630)\tData  0.595 ( 0.967)\tLoss 3.9054e+00 (4.9651e+00)\tAcc@1  18.60 ( 10.26)\tAcc@5  44.60 ( 24.94)\n",
      "Epoch: [0][1600/2563]\tTime  1.794 ( 1.630)\tData  1.139 ( 0.966)\tLoss 3.9303e+00 (4.9317e+00)\tAcc@1  18.60 ( 10.59)\tAcc@5  43.60 ( 25.51)\n",
      "Epoch: [0][1650/2563]\tTime  2.605 ( 1.629)\tData  1.882 ( 0.966)\tLoss 3.9156e+00 (4.8994e+00)\tAcc@1  21.80 ( 10.92)\tAcc@5  43.00 ( 26.09)\n",
      "Epoch: [0][1700/2563]\tTime  2.608 ( 1.630)\tData  1.895 ( 0.966)\tLoss 3.7213e+00 (4.8668e+00)\tAcc@1  23.40 ( 11.26)\tAcc@5  45.00 ( 26.68)\n",
      "Epoch: [0][1750/2563]\tTime  2.443 ( 1.630)\tData  1.752 ( 0.965)\tLoss 3.7847e+00 (4.8352e+00)\tAcc@1  23.40 ( 11.59)\tAcc@5  44.40 ( 27.24)\n",
      "Epoch: [0][1800/2563]\tTime  2.386 ( 1.630)\tData  1.729 ( 0.965)\tLoss 3.7854e+00 (4.8038e+00)\tAcc@1  22.80 ( 11.93)\tAcc@5  45.00 ( 27.79)\n",
      "Epoch: [0][1850/2563]\tTime  2.562 ( 1.630)\tData  1.848 ( 0.964)\tLoss 3.8172e+00 (4.7731e+00)\tAcc@1  20.80 ( 12.26)\tAcc@5  44.20 ( 28.35)\n",
      "Epoch: [0][1900/2563]\tTime  2.528 ( 1.630)\tData  1.828 ( 0.964)\tLoss 3.4248e+00 (4.7427e+00)\tAcc@1  26.60 ( 12.59)\tAcc@5  54.20 ( 28.90)\n",
      "Epoch: [0][1950/2563]\tTime  2.603 ( 1.630)\tData  1.894 ( 0.964)\tLoss 3.6104e+00 (4.7132e+00)\tAcc@1  23.20 ( 12.91)\tAcc@5  50.20 ( 29.43)\n",
      "Epoch: [0][2000/2563]\tTime  2.392 ( 1.630)\tData  1.728 ( 0.964)\tLoss 3.6616e+00 (4.6850e+00)\tAcc@1  25.60 ( 13.21)\tAcc@5  47.80 ( 29.94)\n",
      "Epoch: [0][2050/2563]\tTime  2.839 ( 1.630)\tData  2.114 ( 0.963)\tLoss 3.4384e+00 (4.6567e+00)\tAcc@1  28.40 ( 13.53)\tAcc@5  55.00 ( 30.46)\n",
      "Epoch: [0][2100/2563]\tTime  2.537 ( 1.630)\tData  1.829 ( 0.963)\tLoss 3.6220e+00 (4.6286e+00)\tAcc@1  24.00 ( 13.85)\tAcc@5  47.60 ( 30.97)\n",
      "Epoch: [0][2150/2563]\tTime  2.416 ( 1.629)\tData  1.753 ( 0.962)\tLoss 3.4235e+00 (4.6018e+00)\tAcc@1  29.60 ( 14.16)\tAcc@5  52.60 ( 31.46)\n",
      "Epoch: [0][2200/2563]\tTime  2.495 ( 1.629)\tData  1.829 ( 0.962)\tLoss 3.4620e+00 (4.5757e+00)\tAcc@1  27.20 ( 14.46)\tAcc@5  52.20 ( 31.93)\n",
      "Epoch: [0][2250/2563]\tTime  2.745 ( 1.629)\tData  2.035 ( 0.961)\tLoss 3.3287e+00 (4.5498e+00)\tAcc@1  27.00 ( 14.77)\tAcc@5  58.20 ( 32.41)\n",
      "Epoch: [0][2300/2563]\tTime  2.366 ( 1.628)\tData  1.700 ( 0.960)\tLoss 3.3092e+00 (4.5244e+00)\tAcc@1  30.00 ( 15.06)\tAcc@5  55.40 ( 32.87)\n",
      "Epoch: [0][2350/2563]\tTime  2.709 ( 1.627)\tData  1.979 ( 0.959)\tLoss 3.3830e+00 (4.4997e+00)\tAcc@1  26.20 ( 15.35)\tAcc@5  54.00 ( 33.33)\n",
      "Epoch: [0][2400/2563]\tTime  2.628 ( 1.628)\tData  1.913 ( 0.959)\tLoss 3.3969e+00 (4.4751e+00)\tAcc@1  28.80 ( 15.64)\tAcc@5  53.80 ( 33.77)\n",
      "Epoch: [0][2450/2563]\tTime  2.550 ( 1.627)\tData  1.837 ( 0.958)\tLoss 3.1550e+00 (4.4515e+00)\tAcc@1  31.80 ( 15.93)\tAcc@5  59.80 ( 34.21)\n",
      "Epoch: [0][2500/2563]\tTime  2.647 ( 1.628)\tData  1.938 ( 0.959)\tLoss 3.1470e+00 (4.4279e+00)\tAcc@1  31.40 ( 16.22)\tAcc@5  57.80 ( 34.65)\n",
      "Epoch: [0][2550/2563]\tTime  2.577 ( 1.628)\tData  1.862 ( 0.958)\tLoss 3.2128e+00 (4.4047e+00)\tAcc@1  31.60 ( 16.50)\tAcc@5  58.20 ( 35.07)\n",
      "Test: [  0/100]\tTime  8.109 ( 8.109)\tLoss 3.0171e+00 (3.0171e+00)\tAcc@1  35.20 ( 35.20)\tAcc@5  63.80 ( 63.80)\n",
      "Test: [ 50/100]\tTime  2.841 ( 1.813)\tLoss 4.7553e+00 (3.5801e+00)\tAcc@1  10.00 ( 23.88)\tAcc@5  27.60 ( 50.09)\n",
      " * Acc@1 23.438 Acc@5 48.018\n",
      "lr: [0.05]\n",
      "Epoch: [1][   0/2563]\tTime  4.336 ( 4.336)\tData  3.627 ( 3.627)\tLoss 3.1589e+00 (3.1589e+00)\tAcc@1  31.40 ( 31.40)\tAcc@5  59.20 ( 59.20)\n",
      "Epoch: [1][  50/2563]\tTime  2.375 ( 1.633)\tData  1.715 ( 0.960)\tLoss 3.0042e+00 (3.0420e+00)\tAcc@1  34.60 ( 34.50)\tAcc@5  60.40 ( 59.84)\n",
      "Epoch: [1][ 100/2563]\tTime  2.318 ( 1.588)\tData  1.657 ( 0.918)\tLoss 2.8595e+00 (2.9941e+00)\tAcc@1  37.80 ( 34.77)\tAcc@5  65.60 ( 60.93)\n",
      "Epoch: [1][ 150/2563]\tTime  2.271 ( 1.581)\tData  1.610 ( 0.910)\tLoss 2.8592e+00 (2.9698e+00)\tAcc@1  36.40 ( 35.26)\tAcc@5  61.00 ( 61.38)\n",
      "Epoch: [1][ 200/2563]\tTime  2.409 ( 1.582)\tData  1.745 ( 0.909)\tLoss 2.8985e+00 (2.9559e+00)\tAcc@1  35.80 ( 35.54)\tAcc@5  61.80 ( 61.66)\n",
      "Epoch: [1][ 250/2563]\tTime  2.393 ( 1.580)\tData  1.727 ( 0.907)\tLoss 2.9431e+00 (2.9400e+00)\tAcc@1  38.00 ( 35.71)\tAcc@5  60.80 ( 61.96)\n",
      "Epoch: [1][ 300/2563]\tTime  2.775 ( 1.585)\tData  2.064 ( 0.915)\tLoss 2.7983e+00 (2.9335e+00)\tAcc@1  39.80 ( 35.87)\tAcc@5  64.60 ( 62.12)\n",
      "Epoch: [1][ 350/2563]\tTime  2.022 ( 1.583)\tData  1.387 ( 0.917)\tLoss 2.8428e+00 (2.9272e+00)\tAcc@1  37.00 ( 35.96)\tAcc@5  65.60 ( 62.26)\n",
      "Epoch: [1][ 400/2563]\tTime  0.822 ( 1.580)\tData  0.183 ( 0.918)\tLoss 2.9900e+00 (2.9181e+00)\tAcc@1  36.60 ( 36.10)\tAcc@5  61.20 ( 62.44)\n",
      "Epoch: [1][ 450/2563]\tTime  1.293 ( 1.580)\tData  0.651 ( 0.921)\tLoss 2.7167e+00 (2.9102e+00)\tAcc@1  41.20 ( 36.24)\tAcc@5  66.00 ( 62.61)\n",
      "Epoch: [1][ 500/2563]\tTime  1.239 ( 1.581)\tData  0.606 ( 0.924)\tLoss 2.9982e+00 (2.9036e+00)\tAcc@1  37.00 ( 36.35)\tAcc@5  60.80 ( 62.69)\n",
      "Epoch: [1][ 550/2563]\tTime  0.728 ( 1.581)\tData  0.094 ( 0.926)\tLoss 2.6302e+00 (2.8954e+00)\tAcc@1  39.40 ( 36.48)\tAcc@5  68.80 ( 62.86)\n",
      "Epoch: [1][ 600/2563]\tTime  1.906 ( 1.582)\tData  1.269 ( 0.927)\tLoss 2.9557e+00 (2.8894e+00)\tAcc@1  34.80 ( 36.57)\tAcc@5  60.20 ( 62.94)\n",
      "Epoch: [1][ 650/2563]\tTime  2.338 ( 1.582)\tData  1.695 ( 0.928)\tLoss 2.7874e+00 (2.8829e+00)\tAcc@1  38.20 ( 36.67)\tAcc@5  67.60 ( 63.03)\n",
      "Epoch: [1][ 700/2563]\tTime  1.279 ( 1.580)\tData  0.630 ( 0.927)\tLoss 2.8774e+00 (2.8758e+00)\tAcc@1  36.20 ( 36.78)\tAcc@5  62.40 ( 63.16)\n",
      "Epoch: [1][ 750/2563]\tTime  1.129 ( 1.581)\tData  0.473 ( 0.928)\tLoss 2.7631e+00 (2.8699e+00)\tAcc@1  38.80 ( 36.89)\tAcc@5  67.60 ( 63.25)\n",
      "Epoch: [1][ 800/2563]\tTime  0.763 ( 1.581)\tData  0.105 ( 0.928)\tLoss 2.6598e+00 (2.8630e+00)\tAcc@1  37.60 ( 36.99)\tAcc@5  66.20 ( 63.36)\n",
      "Epoch: [1][ 850/2563]\tTime  1.552 ( 1.581)\tData  0.889 ( 0.928)\tLoss 2.7922e+00 (2.8590e+00)\tAcc@1  36.60 ( 37.05)\tAcc@5  65.00 ( 63.44)\n",
      "Epoch: [1][ 900/2563]\tTime  1.636 ( 1.581)\tData  0.975 ( 0.927)\tLoss 2.4619e+00 (2.8528e+00)\tAcc@1  45.80 ( 37.16)\tAcc@5  68.80 ( 63.56)\n",
      "Epoch: [1][ 950/2563]\tTime  1.993 ( 1.582)\tData  1.328 ( 0.928)\tLoss 2.7631e+00 (2.8468e+00)\tAcc@1  37.40 ( 37.27)\tAcc@5  65.20 ( 63.67)\n",
      "Epoch: [1][1000/2563]\tTime  0.767 ( 1.582)\tData  0.101 ( 0.927)\tLoss 2.7769e+00 (2.8411e+00)\tAcc@1  39.20 ( 37.38)\tAcc@5  64.00 ( 63.77)\n",
      "Epoch: [1][1050/2563]\tTime  0.761 ( 1.582)\tData  0.097 ( 0.927)\tLoss 2.7536e+00 (2.8362e+00)\tAcc@1  34.60 ( 37.45)\tAcc@5  64.40 ( 63.86)\n",
      "Epoch: [1][1100/2563]\tTime  0.769 ( 1.582)\tData  0.102 ( 0.926)\tLoss 2.8044e+00 (2.8300e+00)\tAcc@1  38.00 ( 37.56)\tAcc@5  62.60 ( 63.97)\n",
      "Epoch: [1][1150/2563]\tTime  1.606 ( 1.583)\tData  0.940 ( 0.926)\tLoss 2.9094e+00 (2.8261e+00)\tAcc@1  33.40 ( 37.62)\tAcc@5  64.00 ( 64.05)\n",
      "Epoch: [1][1200/2563]\tTime  2.194 ( 1.583)\tData  1.528 ( 0.926)\tLoss 3.0539e+00 (2.8222e+00)\tAcc@1  34.40 ( 37.71)\tAcc@5  59.60 ( 64.12)\n",
      "Epoch: [1][1250/2563]\tTime  1.618 ( 1.582)\tData  0.953 ( 0.925)\tLoss 2.8978e+00 (2.8182e+00)\tAcc@1  36.40 ( 37.78)\tAcc@5  62.40 ( 64.20)\n",
      "Epoch: [1][1300/2563]\tTime  2.049 ( 1.583)\tData  1.380 ( 0.925)\tLoss 2.7332e+00 (2.8136e+00)\tAcc@1  39.20 ( 37.87)\tAcc@5  65.60 ( 64.27)\n",
      "Epoch: [1][1350/2563]\tTime  2.338 ( 1.583)\tData  1.670 ( 0.924)\tLoss 2.6625e+00 (2.8097e+00)\tAcc@1  42.20 ( 37.96)\tAcc@5  67.20 ( 64.34)\n",
      "Epoch: [1][1400/2563]\tTime  1.333 ( 1.582)\tData  0.668 ( 0.924)\tLoss 2.6400e+00 (2.8048e+00)\tAcc@1  40.60 ( 38.04)\tAcc@5  68.60 ( 64.41)\n",
      "Epoch: [1][1450/2563]\tTime  1.369 ( 1.582)\tData  0.704 ( 0.924)\tLoss 2.6246e+00 (2.7995e+00)\tAcc@1  40.40 ( 38.14)\tAcc@5  69.60 ( 64.51)\n",
      "Epoch: [1][1500/2563]\tTime  0.664 ( 1.583)\tData  0.002 ( 0.923)\tLoss 2.5445e+00 (2.7946e+00)\tAcc@1  42.00 ( 38.22)\tAcc@5  69.20 ( 64.60)\n",
      "Epoch: [1][1550/2563]\tTime  0.673 ( 1.583)\tData  0.003 ( 0.923)\tLoss 2.5763e+00 (2.7898e+00)\tAcc@1  39.00 ( 38.30)\tAcc@5  70.00 ( 64.69)\n",
      "Epoch: [1][1600/2563]\tTime  0.668 ( 1.583)\tData  0.002 ( 0.923)\tLoss 2.5728e+00 (2.7854e+00)\tAcc@1  42.60 ( 38.38)\tAcc@5  68.00 ( 64.77)\n",
      "Epoch: [1][1650/2563]\tTime  0.672 ( 1.584)\tData  0.002 ( 0.923)\tLoss 2.5303e+00 (2.7806e+00)\tAcc@1  41.20 ( 38.46)\tAcc@5  69.80 ( 64.86)\n",
      "Epoch: [1][1700/2563]\tTime  0.670 ( 1.584)\tData  0.002 ( 0.922)\tLoss 2.6008e+00 (2.7754e+00)\tAcc@1  41.20 ( 38.54)\tAcc@5  68.40 ( 64.95)\n",
      "Epoch: [1][1750/2563]\tTime  0.671 ( 1.584)\tData  0.002 ( 0.922)\tLoss 2.6816e+00 (2.7713e+00)\tAcc@1  41.40 ( 38.63)\tAcc@5  66.00 ( 65.02)\n",
      "Epoch: [1][1800/2563]\tTime  0.671 ( 1.584)\tData  0.003 ( 0.922)\tLoss 2.6891e+00 (2.7666e+00)\tAcc@1  43.00 ( 38.70)\tAcc@5  65.00 ( 65.10)\n",
      "Epoch: [1][1850/2563]\tTime  0.667 ( 1.584)\tData  0.002 ( 0.921)\tLoss 2.5419e+00 (2.7621e+00)\tAcc@1  43.00 ( 38.79)\tAcc@5  69.60 ( 65.18)\n",
      "Epoch: [1][1900/2563]\tTime  0.767 ( 1.584)\tData  0.099 ( 0.921)\tLoss 2.4499e+00 (2.7568e+00)\tAcc@1  46.00 ( 38.89)\tAcc@5  70.00 ( 65.26)\n",
      "Epoch: [1][1950/2563]\tTime  0.673 ( 1.584)\tData  0.003 ( 0.921)\tLoss 2.6236e+00 (2.7509e+00)\tAcc@1  39.00 ( 39.00)\tAcc@5  70.20 ( 65.36)\n",
      "Epoch: [1][2000/2563]\tTime  0.668 ( 1.585)\tData  0.003 ( 0.921)\tLoss 2.5137e+00 (2.7463e+00)\tAcc@1  43.80 ( 39.07)\tAcc@5  68.40 ( 65.44)\n",
      "Epoch: [1][2050/2563]\tTime  0.667 ( 1.584)\tData  0.002 ( 0.920)\tLoss 2.7375e+00 (2.7417e+00)\tAcc@1  40.00 ( 39.16)\tAcc@5  66.20 ( 65.52)\n",
      "Epoch: [1][2100/2563]\tTime  0.665 ( 1.585)\tData  0.002 ( 0.920)\tLoss 2.3680e+00 (2.7370e+00)\tAcc@1  43.40 ( 39.25)\tAcc@5  73.60 ( 65.60)\n",
      "Epoch: [1][2150/2563]\tTime  0.669 ( 1.585)\tData  0.002 ( 0.920)\tLoss 2.6312e+00 (2.7331e+00)\tAcc@1  40.20 ( 39.33)\tAcc@5  65.80 ( 65.67)\n",
      "Epoch: [1][2200/2563]\tTime  0.664 ( 1.585)\tData  0.002 ( 0.920)\tLoss 2.3705e+00 (2.7285e+00)\tAcc@1  46.20 ( 39.41)\tAcc@5  73.80 ( 65.75)\n",
      "Epoch: [1][2250/2563]\tTime  0.670 ( 1.585)\tData  0.002 ( 0.919)\tLoss 2.3933e+00 (2.7241e+00)\tAcc@1  47.20 ( 39.49)\tAcc@5  69.00 ( 65.82)\n",
      "Epoch: [1][2300/2563]\tTime  0.670 ( 1.585)\tData  0.002 ( 0.919)\tLoss 2.3955e+00 (2.7194e+00)\tAcc@1  45.20 ( 39.56)\tAcc@5  72.60 ( 65.91)\n",
      "Epoch: [1][2350/2563]\tTime  0.669 ( 1.584)\tData  0.002 ( 0.918)\tLoss 2.5465e+00 (2.7150e+00)\tAcc@1  44.20 ( 39.65)\tAcc@5  71.00 ( 65.99)\n",
      "Epoch: [1][2400/2563]\tTime  0.669 ( 1.584)\tData  0.002 ( 0.918)\tLoss 2.7969e+00 (2.7110e+00)\tAcc@1  41.00 ( 39.73)\tAcc@5  64.00 ( 66.05)\n",
      "Epoch: [1][2450/2563]\tTime  1.165 ( 1.584)\tData  0.501 ( 0.918)\tLoss 2.3521e+00 (2.7069e+00)\tAcc@1  46.40 ( 39.79)\tAcc@5  72.60 ( 66.13)\n",
      "Epoch: [1][2500/2563]\tTime  0.761 ( 1.584)\tData  0.097 ( 0.918)\tLoss 2.7426e+00 (2.7030e+00)\tAcc@1  37.80 ( 39.86)\tAcc@5  63.60 ( 66.19)\n",
      "Epoch: [1][2550/2563]\tTime  0.739 ( 1.584)\tData  0.097 ( 0.918)\tLoss 2.4646e+00 (2.6990e+00)\tAcc@1  42.40 ( 39.93)\tAcc@5  71.00 ( 66.27)\n",
      "Test: [  0/100]\tTime  4.686 ( 4.686)\tLoss 1.9108e+00 (1.9108e+00)\tAcc@1  54.80 ( 54.80)\tAcc@5  82.40 ( 82.40)\n",
      "Test: [ 50/100]\tTime  2.853 ( 1.809)\tLoss 3.6636e+00 (2.6711e+00)\tAcc@1  23.00 ( 38.66)\tAcc@5  48.40 ( 67.54)\n",
      " * Acc@1 36.948 Acc@5 63.722\n",
      "lr: [0.0]\n",
      "CPU times: user 1h 3min 32s, sys: 4min 14s, total: 1h 7min 47s\n",
      "Wall time: 2h 23min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})\n",
    "    \n",
    "# print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adc68068",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/data/runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
