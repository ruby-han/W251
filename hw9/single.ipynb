{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2513038",
   "metadata": {
    "executionInfo": {
     "elapsed": 4198,
     "status": "ok",
     "timestamp": 1624759883403,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "f2513038"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dad9dde",
   "metadata": {},
   "source": [
    "### Automatic Mixed Precision (AMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bf93824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca39e242",
   "metadata": {},
   "source": [
    "### Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2296e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"/data/runs/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a95f389",
   "metadata": {},
   "source": [
    "### Weights and Biases (wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4f55eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrubyhan\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb72e29",
   "metadata": {
    "id": "8cb72e29"
   },
   "outputs": [],
   "source": [
    "GPU=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d1a0c0",
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1624759889299,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "02d1a0c0"
   },
   "outputs": [],
   "source": [
    "SEED=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b262f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_step=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b9bfde",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1624759891917,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "b1b9bfde"
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b270c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "129b73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74ea7196",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not torch.cuda.is_available():\n",
    "    print('GPU not detected.. did you pass through your GPU?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9eb47a7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1624759894660,
     "user": {
      "displayName": "Dima Rekesh",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCxhnQN9cW764WS8AiJguM8wE5foCZLMjr-NyFuQ=s64",
      "userId": "05362657998610812765"
     },
     "user_tz": 420
    },
    "id": "e9eb47a7",
    "outputId": "c49775ff-91ee-488c-d99c-3739e452d6af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "073b7b81",
   "metadata": {
    "id": "073b7b81"
   },
   "outputs": [],
   "source": [
    "START_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e18ae51",
   "metadata": {
    "id": "5e18ae51",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ARCH = 'resnet18'\n",
    "# ARCH = 'resnet152'\n",
    "EPOCHS = 2 #200\n",
    "LR = 0.1\n",
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 1e-4\n",
    "PRINT_FREQ = 50\n",
    "TRAIN_BATCH=500 #128\n",
    "VAL_BATCH=500 #128\n",
    "WORKERS=2\n",
    "TRAINDIR=\"/data/hw9/train\"\n",
    "VALDIR=\"/data/hw9/val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0efdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaEnvException: Unable to determine environment\n",
      "\n",
      "Please re-run this command with one of the following options:\n",
      "\n",
      "* Provide an environment name via --name or -n\n",
      "* Re-run this command inside an activated conda environment.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/rubyhan/hw9_single/runs/3ojzz548\" target=\"_blank\">good-salad-10</a></strong> to <a href=\"https://wandb.ai/rubyhan/hw9_single\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/rubyhan/hw9_single/runs/3ojzz548?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f441735b340>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='hw9_single', \n",
    "           entity='rubyhan', \n",
    "           config = {\n",
    "               \"learning_rate\": LR,\n",
    "               \"epochs\": EPOCHS,\n",
    "               \"batch_size\": TRAIN_BATCH,\n",
    "               \"momentum\": MOMENTUM, \n",
    "               \"weight_decay\": WEIGHT_DECAY,\n",
    "               \"architecture\": ARCH\n",
    "           })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88d42a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    global global_step\n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, losses, top1, top5],\n",
    "        prefix=\"Epoch: [{}]\".format(epoch))\n",
    "\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    \n",
    "    \n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "#         # compute output\n",
    "#         output = model(images)\n",
    "#         loss = criterion(output, target)\n",
    "        \n",
    "        # WITH AMP\n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "\n",
    "#         # compute gradient and do SGD step\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "        # use the scaler\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        writer.add_scalar(\"Loss/train\", loss, global_step = global_step)\n",
    "        writer.add_scalar(\"acc1/train\", top1.avg, global_step = global_step)\n",
    "        writer.add_scalar(\"acc5/train\", top5.avg, global_step = global_step)\n",
    "        global_step += 1\n",
    "        \n",
    "        wandb.log({\"Loss/train\": loss, \"acc1/train\": top1.avg, \"acc5/train\": top5.avg})\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab30a1a4",
   "metadata": {
    "id": "ab30a1a4"
   },
   "outputs": [],
   "source": [
    "def validate(val_loader, model, criterion):\n",
    "    global global_step\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(val_loader),\n",
    "        [batch_time, losses, top1, top5],\n",
    "        prefix='Test: ')\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        end = time.time()\n",
    "        for i, (images, target) in enumerate(val_loader):\n",
    "            if GPU is not None:\n",
    "                images = images.cuda(GPU, non_blocking=True)\n",
    "            if torch.cuda.is_available():\n",
    "                target = target.cuda(GPU, non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            losses.update(loss.item(), images.size(0))\n",
    "            top1.update(acc1[0], images.size(0))\n",
    "            top5.update(acc5[0], images.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % PRINT_FREQ == 0:\n",
    "                progress.display(i)\n",
    "\n",
    "        # TODO: this should also be done with the ProgressMeter\n",
    "        print(' * Acc@1 {top1.avg:.3f} Acc@5 {top5.avg:.3f}'\n",
    "              .format(top1=top1, top5=top5))\n",
    "    \n",
    "    writer.add_scalar(\"Loss/val\", losses.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc1/val\", top1.avg, global_step = global_step)\n",
    "    writer.add_scalar(\"acc5/val\", top5.avg, global_step = global_step)    \n",
    "    \n",
    "    wandb.log({\"Loss/val\": losses.avg, 'acc1/val': top1.avg, 'acc5/val': top5.avg})\n",
    "    \n",
    "    return top1.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afa7d9fd",
   "metadata": {
    "id": "afa7d9fd"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c5f0ab4",
   "metadata": {
    "id": "8c5f0ab4"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce30c86a",
   "metadata": {
    "id": "ce30c86a"
   },
   "outputs": [],
   "source": [
    "class ProgressMeter(object):\n",
    "    def __init__(self, num_batches, meters, prefix=\"\"):\n",
    "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
    "        self.meters = meters\n",
    "        self.prefix = prefix\n",
    "\n",
    "    def display(self, batch):\n",
    "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
    "        entries += [str(meter) for meter in self.meters]\n",
    "        print('\\t'.join(entries))\n",
    "\n",
    "    def _get_batch_fmtstr(self, num_batches):\n",
    "        num_digits = len(str(num_batches // 1))\n",
    "        fmt = '{:' + str(num_digits) + 'd}'\n",
    "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7504ce7a",
   "metadata": {
    "id": "7504ce7a"
   },
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = LR * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d659923",
   "metadata": {
    "id": "0d659923"
   },
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f74f06e1",
   "metadata": {
    "id": "f74f06e1"
   },
   "outputs": [],
   "source": [
    "imagenet_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "imagenet_std_RGB = [0.229, 0.224, 0.225]\n",
    "cinic_mean_RGB = [0.47889522, 0.47227842, 0.43047404]\n",
    "cinic_std_RGB = [0.24205776, 0.23828046, 0.25874835]\n",
    "cifar_mean_RGB = [0.4914, 0.4822, 0.4465]\n",
    "cifar_std_RGB = [0.2023, 0.1994, 0.2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c005e2dd",
   "metadata": {
    "id": "c005e2dd"
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=imagenet_mean_RGB, \n",
    "                                 std=imagenet_std_RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29d54592",
   "metadata": {
    "id": "29d54592"
   },
   "outputs": [],
   "source": [
    "# IMG_SIZE = 32\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "94059b7f",
   "metadata": {
    "id": "94059b7f"
   },
   "outputs": [],
   "source": [
    "NUM_CLASSES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "788c0401",
   "metadata": {
    "id": "788c0401"
   },
   "outputs": [],
   "source": [
    "model = models.__dict__[ARCH]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63dc579e",
   "metadata": {
    "id": "63dc579e"
   },
   "outputs": [],
   "source": [
    "inf = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "edf9cf5d",
   "metadata": {
    "id": "edf9cf5d"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(inf, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319e2d99",
   "metadata": {
    "id": "319e2d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8dc59b5",
   "metadata": {
    "id": "b8dc59b5"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3999d84a",
   "metadata": {
    "id": "3999d84a"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), LR,\n",
    "                                momentum=MOMENTUM,\n",
    "                                weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9fae338b",
   "metadata": {
    "id": "9fae338b"
   },
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "34dbcdb1",
   "metadata": {
    "id": "34dbcdb1"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5275a69",
   "metadata": {
    "id": "e5275a69"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "    TRAINDIR, transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "854ca1ad",
   "metadata": {
    "id": "854ca1ad"
   },
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(imagenet_mean_RGB, imagenet_std_RGB),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abfa5fb6",
   "metadata": {
    "id": "abfa5fb6"
   },
   "outputs": [],
   "source": [
    "val_dataset = datasets.ImageFolder(\n",
    "    VALDIR, transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07a0bdf4",
   "metadata": {
    "id": "07a0bdf4"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH, shuffle=True,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "192ae835",
   "metadata": {
    "id": "192ae835"
   },
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(\n",
    "        val_dataset, batch_size=VAL_BATCH, shuffle=False,\n",
    "        num_workers=WORKERS, pin_memory=True, sampler=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1502c5db",
   "metadata": {
    "id": "1502c5db"
   },
   "outputs": [],
   "source": [
    "best_acc1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e37e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "\n",
    "def find_lr(init_value = 1e-8, final_value=10., beta = 0.98):\n",
    "    num = len(train_loader)-1\n",
    "    mult = (final_value / init_value) ** (1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr\n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    batch_time = AverageMeter('Time', ':6.3f')\n",
    "    data_time = AverageMeter('Data', ':6.3f')\n",
    "    meter_losses = AverageMeter('Loss', ':.4e')\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    progress = ProgressMeter(\n",
    "        len(train_loader),\n",
    "        [batch_time, data_time, meter_losses, top1, top5])\n",
    "    \n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "        batch_num += 1\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if GPU is not None:\n",
    "            images = images.cuda(GPU, non_blocking=True)\n",
    "        if torch.cuda.is_available():\n",
    "            target = target.cuda(GPU, non_blocking=True)\n",
    "        \n",
    "        with autocast():\n",
    "            # compute output\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "        meter_losses.update(loss.item(), images.size(0))\n",
    "        top1.update(acc1[0], images.size(0))\n",
    "        top5.update(acc5[0], images.size(0))\n",
    "        \n",
    "        #Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        #Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        #Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "            \n",
    "        #Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        \n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        #Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        \n",
    "        if i % PRINT_FREQ == 0:\n",
    "            progress.display(i)\n",
    "        \n",
    "    return log_lrs, losses\n",
    "\n",
    "# logs,losses = find_lr()\n",
    "# plt.plot(logs[10:-5],losses[10:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ceb95e07",
   "metadata": {
    "id": "ceb95e07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][   0/2563]\tTime 15.658 (15.658)\tData  3.892 ( 3.892)\tLoss 7.0159e+00 (7.0159e+00)\tAcc@1   0.20 (  0.20)\tAcc@5   0.60 (  0.60)\n",
      "Epoch: [0][  50/2563]\tTime  1.593 ( 1.806)\tData  0.943 ( 0.934)\tLoss 6.7629e+00 (6.9218e+00)\tAcc@1   0.00 (  0.29)\tAcc@5   2.20 (  1.31)\n",
      "Epoch: [0][ 100/2563]\tTime  1.304 ( 1.704)\tData  0.645 ( 0.939)\tLoss 6.5557e+00 (6.7646e+00)\tAcc@1   0.20 (  0.53)\tAcc@5   2.80 (  2.16)\n",
      "Epoch: [0][ 150/2563]\tTime  1.069 ( 1.668)\tData  0.403 ( 0.938)\tLoss 6.3213e+00 (6.6301e+00)\tAcc@1   0.80 (  0.77)\tAcc@5   4.40 (  3.06)\n",
      "Epoch: [0][ 200/2563]\tTime  0.667 ( 1.658)\tData  0.002 ( 0.942)\tLoss 6.0014e+00 (6.5112e+00)\tAcc@1   2.40 (  1.02)\tAcc@5   7.80 (  3.86)\n",
      "Epoch: [0][ 250/2563]\tTime  0.675 ( 1.650)\tData  0.002 ( 0.941)\tLoss 5.8253e+00 (6.4050e+00)\tAcc@1   2.00 (  1.32)\tAcc@5  10.00 (  4.76)\n",
      "Epoch: [0][ 300/2563]\tTime  0.676 ( 1.643)\tData  0.002 ( 0.938)\tLoss 5.7295e+00 (6.3136e+00)\tAcc@1   2.80 (  1.56)\tAcc@5  10.60 (  5.52)\n",
      "Epoch: [0][ 350/2563]\tTime  0.669 ( 1.638)\tData  0.002 ( 0.936)\tLoss 5.6014e+00 (6.2255e+00)\tAcc@1   3.80 (  1.88)\tAcc@5  12.60 (  6.40)\n",
      "Epoch: [0][ 400/2563]\tTime  0.642 ( 1.633)\tData  0.003 ( 0.935)\tLoss 5.4148e+00 (6.1422e+00)\tAcc@1   5.00 (  2.20)\tAcc@5  15.80 (  7.31)\n",
      "Epoch: [0][ 450/2563]\tTime  0.638 ( 1.632)\tData  0.003 ( 0.938)\tLoss 5.3926e+00 (6.0633e+00)\tAcc@1   5.00 (  2.52)\tAcc@5  18.40 (  8.22)\n",
      "Epoch: [0][ 500/2563]\tTime  0.640 ( 1.629)\tData  0.002 ( 0.939)\tLoss 5.2547e+00 (5.9877e+00)\tAcc@1   6.60 (  2.87)\tAcc@5  20.00 (  9.14)\n",
      "Epoch: [0][ 550/2563]\tTime  0.641 ( 1.627)\tData  0.002 ( 0.940)\tLoss 5.1756e+00 (5.9175e+00)\tAcc@1   6.40 (  3.21)\tAcc@5  21.20 ( 10.05)\n",
      "Epoch: [0][ 600/2563]\tTime  0.640 ( 1.625)\tData  0.002 ( 0.940)\tLoss 5.0330e+00 (5.8502e+00)\tAcc@1   8.00 (  3.55)\tAcc@5  23.60 ( 10.94)\n",
      "Epoch: [0][ 650/2563]\tTime  0.638 ( 1.625)\tData  0.002 ( 0.942)\tLoss 4.9699e+00 (5.7881e+00)\tAcc@1   9.60 (  3.89)\tAcc@5  23.40 ( 11.75)\n",
      "Epoch: [0][ 700/2563]\tTime  0.643 ( 1.624)\tData  0.002 ( 0.943)\tLoss 5.0180e+00 (5.7283e+00)\tAcc@1   7.80 (  4.24)\tAcc@5  23.60 ( 12.60)\n",
      "Epoch: [0][ 750/2563]\tTime  0.645 ( 1.623)\tData  0.002 ( 0.943)\tLoss 4.7574e+00 (5.6693e+00)\tAcc@1  11.00 (  4.61)\tAcc@5  28.00 ( 13.44)\n",
      "Epoch: [0][ 800/2563]\tTime  0.638 ( 1.623)\tData  0.003 ( 0.944)\tLoss 4.6132e+00 (5.6138e+00)\tAcc@1  13.40 (  4.97)\tAcc@5  27.80 ( 14.25)\n",
      "Epoch: [0][ 850/2563]\tTime  0.667 ( 1.622)\tData  0.002 ( 0.945)\tLoss 4.5731e+00 (5.5603e+00)\tAcc@1  11.80 (  5.33)\tAcc@5  29.60 ( 15.08)\n",
      "Epoch: [0][ 900/2563]\tTime  0.640 ( 1.622)\tData  0.003 ( 0.946)\tLoss 4.4554e+00 (5.5081e+00)\tAcc@1  12.00 (  5.71)\tAcc@5  33.40 ( 15.88)\n",
      "Epoch: [0][ 950/2563]\tTime  0.647 ( 1.623)\tData  0.002 ( 0.948)\tLoss 4.6507e+00 (5.4579e+00)\tAcc@1  10.60 (  6.08)\tAcc@5  29.20 ( 16.66)\n",
      "Epoch: [0][1000/2563]\tTime  0.649 ( 1.625)\tData  0.002 ( 0.951)\tLoss 4.4606e+00 (5.4104e+00)\tAcc@1  12.80 (  6.45)\tAcc@5  32.20 ( 17.42)\n",
      "Epoch: [0][1050/2563]\tTime  0.655 ( 1.628)\tData  0.002 ( 0.953)\tLoss 4.5248e+00 (5.3642e+00)\tAcc@1  12.40 (  6.80)\tAcc@5  30.60 ( 18.15)\n",
      "Epoch: [0][1100/2563]\tTime  0.657 ( 1.629)\tData  0.003 ( 0.955)\tLoss 4.2872e+00 (5.3183e+00)\tAcc@1  16.20 (  7.18)\tAcc@5  37.40 ( 18.91)\n",
      "Epoch: [0][1150/2563]\tTime  0.663 ( 1.630)\tData  0.003 ( 0.956)\tLoss 4.3142e+00 (5.2741e+00)\tAcc@1  13.60 (  7.54)\tAcc@5  36.60 ( 19.65)\n",
      "Epoch: [0][1200/2563]\tTime  0.664 ( 1.632)\tData  0.002 ( 0.957)\tLoss 4.1933e+00 (5.2307e+00)\tAcc@1  19.00 (  7.90)\tAcc@5  39.20 ( 20.38)\n",
      "Epoch: [0][1250/2563]\tTime  0.673 ( 1.632)\tData  0.002 ( 0.957)\tLoss 4.1213e+00 (5.1890e+00)\tAcc@1  19.80 (  8.27)\tAcc@5  39.80 ( 21.07)\n",
      "Epoch: [0][1300/2563]\tTime  0.670 ( 1.632)\tData  0.002 ( 0.957)\tLoss 4.1174e+00 (5.1484e+00)\tAcc@1  19.60 (  8.64)\tAcc@5  39.80 ( 21.76)\n",
      "Epoch: [0][1350/2563]\tTime  0.640 ( 1.631)\tData  0.002 ( 0.957)\tLoss 3.9646e+00 (5.1092e+00)\tAcc@1  21.20 (  9.00)\tAcc@5  41.00 ( 22.43)\n",
      "Epoch: [0][1400/2563]\tTime  0.638 ( 1.631)\tData  0.002 ( 0.957)\tLoss 3.9073e+00 (5.0706e+00)\tAcc@1  19.20 (  9.36)\tAcc@5  46.60 ( 23.09)\n",
      "Epoch: [0][1450/2563]\tTime  0.643 ( 1.632)\tData  0.002 ( 0.959)\tLoss 4.0947e+00 (5.0332e+00)\tAcc@1  17.20 (  9.72)\tAcc@5  42.00 ( 23.75)\n",
      "Epoch: [0][1500/2563]\tTime  0.638 ( 1.632)\tData  0.002 ( 0.959)\tLoss 3.8952e+00 (4.9972e+00)\tAcc@1  21.00 ( 10.06)\tAcc@5  45.60 ( 24.40)\n",
      "Epoch: [0][1550/2563]\tTime  0.638 ( 1.632)\tData  0.002 ( 0.960)\tLoss 3.8889e+00 (4.9609e+00)\tAcc@1  20.00 ( 10.42)\tAcc@5  43.80 ( 25.04)\n",
      "Epoch: [0][1600/2563]\tTime  0.637 ( 1.632)\tData  0.002 ( 0.960)\tLoss 3.8508e+00 (4.9262e+00)\tAcc@1  20.80 ( 10.76)\tAcc@5  43.80 ( 25.64)\n",
      "Epoch: [0][1650/2563]\tTime  0.644 ( 1.632)\tData  0.003 ( 0.961)\tLoss 3.8113e+00 (4.8928e+00)\tAcc@1  23.20 ( 11.10)\tAcc@5  44.00 ( 26.24)\n",
      "Epoch: [0][1700/2563]\tTime  0.732 ( 1.632)\tData  0.098 ( 0.961)\tLoss 3.7057e+00 (4.8593e+00)\tAcc@1  22.80 ( 11.44)\tAcc@5  48.00 ( 26.84)\n",
      "Epoch: [0][1750/2563]\tTime  0.637 ( 1.633)\tData  0.002 ( 0.962)\tLoss 3.6992e+00 (4.8267e+00)\tAcc@1  23.20 ( 11.78)\tAcc@5  46.80 ( 27.43)\n",
      "Epoch: [0][1800/2563]\tTime  0.638 ( 1.633)\tData  0.003 ( 0.963)\tLoss 3.7388e+00 (4.7951e+00)\tAcc@1  22.20 ( 12.12)\tAcc@5  45.60 ( 27.99)\n",
      "Epoch: [0][1850/2563]\tTime  0.645 ( 1.633)\tData  0.003 ( 0.963)\tLoss 3.7258e+00 (4.7637e+00)\tAcc@1  23.20 ( 12.45)\tAcc@5  45.40 ( 28.56)\n",
      "Epoch: [0][1900/2563]\tTime  0.653 ( 1.634)\tData  0.002 ( 0.964)\tLoss 3.3872e+00 (4.7326e+00)\tAcc@1  30.40 ( 12.79)\tAcc@5  53.40 ( 29.12)\n",
      "Epoch: [0][1950/2563]\tTime  0.811 ( 1.635)\tData  0.160 ( 0.965)\tLoss 3.5614e+00 (4.7024e+00)\tAcc@1  22.20 ( 13.11)\tAcc@5  49.40 ( 29.66)\n",
      "Epoch: [0][2000/2563]\tTime  0.660 ( 1.635)\tData  0.002 ( 0.965)\tLoss 3.5728e+00 (4.6733e+00)\tAcc@1  26.20 ( 13.43)\tAcc@5  48.60 ( 30.18)\n",
      "Epoch: [0][2050/2563]\tTime  1.191 ( 1.635)\tData  0.530 ( 0.965)\tLoss 3.4197e+00 (4.6445e+00)\tAcc@1  26.80 ( 13.75)\tAcc@5  53.60 ( 30.70)\n",
      "Epoch: [0][2100/2563]\tTime  0.870 ( 1.635)\tData  0.203 ( 0.965)\tLoss 3.5719e+00 (4.6159e+00)\tAcc@1  25.00 ( 14.07)\tAcc@5  49.80 ( 31.22)\n",
      "Epoch: [0][2150/2563]\tTime  0.666 ( 1.636)\tData  0.003 ( 0.965)\tLoss 3.3438e+00 (4.5885e+00)\tAcc@1  29.60 ( 14.39)\tAcc@5  53.60 ( 31.72)\n",
      "Epoch: [0][2200/2563]\tTime  0.667 ( 1.636)\tData  0.002 ( 0.965)\tLoss 3.4901e+00 (4.5620e+00)\tAcc@1  27.60 ( 14.70)\tAcc@5  53.40 ( 32.21)\n",
      "Epoch: [0][2250/2563]\tTime  0.639 ( 1.636)\tData  0.002 ( 0.965)\tLoss 3.3374e+00 (4.5357e+00)\tAcc@1  26.60 ( 15.00)\tAcc@5  56.20 ( 32.69)\n",
      "Epoch: [0][2300/2563]\tTime  0.637 ( 1.636)\tData  0.002 ( 0.966)\tLoss 3.2452e+00 (4.5100e+00)\tAcc@1  30.40 ( 15.30)\tAcc@5  54.80 ( 33.15)\n",
      "Epoch: [0][2350/2563]\tTime  0.639 ( 1.636)\tData  0.002 ( 0.966)\tLoss 3.2794e+00 (4.4848e+00)\tAcc@1  28.60 ( 15.59)\tAcc@5  56.20 ( 33.61)\n",
      "Epoch: [0][2400/2563]\tTime  0.643 ( 1.636)\tData  0.002 ( 0.966)\tLoss 3.3616e+00 (4.4599e+00)\tAcc@1  25.80 ( 15.88)\tAcc@5  54.00 ( 34.07)\n",
      "Epoch: [0][2450/2563]\tTime  0.648 ( 1.636)\tData  0.002 ( 0.967)\tLoss 3.1185e+00 (4.4362e+00)\tAcc@1  32.00 ( 16.16)\tAcc@5  59.00 ( 34.51)\n",
      "Epoch: [0][2500/2563]\tTime  0.652 ( 1.635)\tData  0.002 ( 0.966)\tLoss 3.1120e+00 (4.4124e+00)\tAcc@1  31.00 ( 16.46)\tAcc@5  59.60 ( 34.95)\n",
      "Epoch: [0][2550/2563]\tTime  0.662 ( 1.636)\tData  0.002 ( 0.967)\tLoss 3.2632e+00 (4.3889e+00)\tAcc@1  30.20 ( 16.74)\tAcc@5  55.00 ( 35.38)\n",
      "Test: [  0/100]\tTime  8.064 ( 8.064)\tLoss 3.0867e+00 (3.0867e+00)\tAcc@1  37.40 ( 37.40)\tAcc@5  63.00 ( 63.00)\n",
      "Test: [ 50/100]\tTime  2.701 ( 1.825)\tLoss 4.3186e+00 (3.4822e+00)\tAcc@1  16.20 ( 25.65)\tAcc@5  36.20 ( 52.19)\n",
      " * Acc@1 24.924 Acc@5 49.752\n",
      "lr: [0.05]\n",
      "Epoch: [1][   0/2563]\tTime  4.493 ( 4.493)\tData  3.786 ( 3.786)\tLoss 3.1015e+00 (3.1015e+00)\tAcc@1  32.40 ( 32.40)\tAcc@5  58.80 ( 58.80)\n",
      "Epoch: [1][  50/2563]\tTime  2.490 ( 1.661)\tData  1.780 ( 0.990)\tLoss 2.9376e+00 (3.0027e+00)\tAcc@1  34.40 ( 34.77)\tAcc@5  60.40 ( 60.61)\n",
      "Epoch: [1][ 100/2563]\tTime  1.862 ( 1.616)\tData  1.203 ( 0.948)\tLoss 2.8279e+00 (2.9567e+00)\tAcc@1  37.00 ( 35.28)\tAcc@5  64.80 ( 61.55)\n",
      "Epoch: [1][ 150/2563]\tTime  2.344 ( 1.611)\tData  1.680 ( 0.944)\tLoss 2.8415e+00 (2.9339e+00)\tAcc@1  37.80 ( 35.75)\tAcc@5  65.80 ( 62.05)\n",
      "Epoch: [1][ 200/2563]\tTime  2.119 ( 1.612)\tData  1.454 ( 0.944)\tLoss 2.8188e+00 (2.9203e+00)\tAcc@1  38.20 ( 35.99)\tAcc@5  64.80 ( 62.34)\n",
      "Epoch: [1][ 250/2563]\tTime  0.965 ( 1.608)\tData  0.294 ( 0.940)\tLoss 2.9226e+00 (2.9039e+00)\tAcc@1  36.60 ( 36.17)\tAcc@5  62.80 ( 62.65)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1][ 300/2563]\tTime  1.633 ( 1.611)\tData  0.970 ( 0.942)\tLoss 2.8529e+00 (2.8992e+00)\tAcc@1  39.40 ( 36.32)\tAcc@5  62.60 ( 62.74)\n",
      "Epoch: [1][ 350/2563]\tTime  0.769 ( 1.610)\tData  0.107 ( 0.941)\tLoss 2.8453e+00 (2.8929e+00)\tAcc@1  37.80 ( 36.41)\tAcc@5  66.60 ( 62.84)\n",
      "Epoch: [1][ 400/2563]\tTime  0.669 ( 1.609)\tData  0.002 ( 0.939)\tLoss 2.8969e+00 (2.8835e+00)\tAcc@1  38.00 ( 36.60)\tAcc@5  64.60 ( 63.04)\n",
      "Epoch: [1][ 450/2563]\tTime  0.765 ( 1.608)\tData  0.096 ( 0.936)\tLoss 2.6394e+00 (2.8744e+00)\tAcc@1  42.40 ( 36.79)\tAcc@5  68.20 ( 63.21)\n",
      "Epoch: [1][ 500/2563]\tTime  0.766 ( 1.608)\tData  0.101 ( 0.936)\tLoss 2.9746e+00 (2.8675e+00)\tAcc@1  35.60 ( 36.91)\tAcc@5  60.80 ( 63.32)\n",
      "Epoch: [1][ 550/2563]\tTime  0.668 ( 1.610)\tData  0.002 ( 0.937)\tLoss 2.6190e+00 (2.8605e+00)\tAcc@1  41.00 ( 37.04)\tAcc@5  69.20 ( 63.43)\n",
      "Epoch: [1][ 600/2563]\tTime  1.284 ( 1.609)\tData  0.615 ( 0.936)\tLoss 2.9487e+00 (2.8546e+00)\tAcc@1  33.60 ( 37.10)\tAcc@5  60.20 ( 63.49)\n",
      "Epoch: [1][ 650/2563]\tTime  2.237 ( 1.610)\tData  1.572 ( 0.938)\tLoss 2.7513e+00 (2.8486e+00)\tAcc@1  39.80 ( 37.19)\tAcc@5  65.40 ( 63.58)\n",
      "Epoch: [1][ 700/2563]\tTime  1.163 ( 1.608)\tData  0.499 ( 0.936)\tLoss 2.8485e+00 (2.8422e+00)\tAcc@1  39.40 ( 37.29)\tAcc@5  63.20 ( 63.70)\n",
      "Epoch: [1][ 750/2563]\tTime  0.962 ( 1.607)\tData  0.295 ( 0.936)\tLoss 2.7342e+00 (2.8366e+00)\tAcc@1  39.60 ( 37.39)\tAcc@5  67.00 ( 63.79)\n",
      "Epoch: [1][ 800/2563]\tTime  0.765 ( 1.607)\tData  0.099 ( 0.936)\tLoss 2.7279e+00 (2.8306e+00)\tAcc@1  36.40 ( 37.48)\tAcc@5  67.60 ( 63.90)\n",
      "Epoch: [1][ 850/2563]\tTime  1.257 ( 1.607)\tData  0.610 ( 0.936)\tLoss 2.7716e+00 (2.8264e+00)\tAcc@1  37.80 ( 37.55)\tAcc@5  65.20 ( 63.98)\n",
      "Epoch: [1][ 900/2563]\tTime  1.428 ( 1.608)\tData  0.793 ( 0.939)\tLoss 2.4827e+00 (2.8203e+00)\tAcc@1  42.20 ( 37.67)\tAcc@5  69.40 ( 64.10)\n",
      "Epoch: [1][ 950/2563]\tTime  1.540 ( 1.609)\tData  0.906 ( 0.941)\tLoss 2.7538e+00 (2.8143e+00)\tAcc@1  37.20 ( 37.78)\tAcc@5  63.60 ( 64.20)\n",
      "Epoch: [1][1000/2563]\tTime  0.642 ( 1.608)\tData  0.002 ( 0.942)\tLoss 2.7195e+00 (2.8090e+00)\tAcc@1  40.80 ( 37.87)\tAcc@5  65.80 ( 64.31)\n",
      "Epoch: [1][1050/2563]\tTime  0.651 ( 1.609)\tData  0.002 ( 0.943)\tLoss 2.7332e+00 (2.8043e+00)\tAcc@1  36.40 ( 37.94)\tAcc@5  67.00 ( 64.39)\n",
      "Epoch: [1][1100/2563]\tTime  0.652 ( 1.608)\tData  0.003 ( 0.943)\tLoss 2.7420e+00 (2.7981e+00)\tAcc@1  39.80 ( 38.06)\tAcc@5  64.60 ( 64.50)\n",
      "Epoch: [1][1150/2563]\tTime  0.781 ( 1.608)\tData  0.128 ( 0.943)\tLoss 2.8845e+00 (2.7944e+00)\tAcc@1  36.20 ( 38.14)\tAcc@5  64.40 ( 64.58)\n",
      "Epoch: [1][1200/2563]\tTime  1.574 ( 1.609)\tData  0.915 ( 0.944)\tLoss 3.0148e+00 (2.7907e+00)\tAcc@1  37.60 ( 38.22)\tAcc@5  62.40 ( 64.65)\n",
      "Epoch: [1][1250/2563]\tTime  1.151 ( 1.609)\tData  0.492 ( 0.944)\tLoss 2.8536e+00 (2.7869e+00)\tAcc@1  36.60 ( 38.28)\tAcc@5  65.80 ( 64.73)\n",
      "Epoch: [1][1300/2563]\tTime  2.318 ( 1.609)\tData  1.652 ( 0.944)\tLoss 2.7073e+00 (2.7823e+00)\tAcc@1  40.60 ( 38.36)\tAcc@5  65.80 ( 64.81)\n",
      "Epoch: [1][1350/2563]\tTime  2.478 ( 1.609)\tData  1.772 ( 0.944)\tLoss 2.6476e+00 (2.7788e+00)\tAcc@1  44.40 ( 38.44)\tAcc@5  65.80 ( 64.86)\n",
      "Epoch: [1][1400/2563]\tTime  1.655 ( 1.608)\tData  0.992 ( 0.943)\tLoss 2.6418e+00 (2.7737e+00)\tAcc@1  39.80 ( 38.52)\tAcc@5  66.20 ( 64.94)\n",
      "Epoch: [1][1450/2563]\tTime  1.693 ( 1.608)\tData  1.029 ( 0.943)\tLoss 2.6131e+00 (2.7685e+00)\tAcc@1  39.60 ( 38.61)\tAcc@5  68.00 ( 65.04)\n",
      "Epoch: [1][1500/2563]\tTime  0.777 ( 1.607)\tData  0.110 ( 0.942)\tLoss 2.4721e+00 (2.7636e+00)\tAcc@1  44.60 ( 38.71)\tAcc@5  70.60 ( 65.12)\n",
      "Epoch: [1][1550/2563]\tTime  0.674 ( 1.607)\tData  0.003 ( 0.942)\tLoss 2.5307e+00 (2.7587e+00)\tAcc@1  42.40 ( 38.80)\tAcc@5  68.20 ( 65.22)\n",
      "Epoch: [1][1600/2563]\tTime  0.671 ( 1.607)\tData  0.002 ( 0.941)\tLoss 2.6007e+00 (2.7542e+00)\tAcc@1  41.60 ( 38.89)\tAcc@5  67.20 ( 65.29)\n",
      "Epoch: [1][1650/2563]\tTime  0.675 ( 1.607)\tData  0.002 ( 0.941)\tLoss 2.5336e+00 (2.7491e+00)\tAcc@1  41.80 ( 38.98)\tAcc@5  69.40 ( 65.38)\n",
      "Epoch: [1][1700/2563]\tTime  0.671 ( 1.607)\tData  0.002 ( 0.941)\tLoss 2.5820e+00 (2.7443e+00)\tAcc@1  41.00 ( 39.05)\tAcc@5  68.20 ( 65.45)\n",
      "Epoch: [1][1750/2563]\tTime  0.674 ( 1.607)\tData  0.002 ( 0.940)\tLoss 2.6553e+00 (2.7402e+00)\tAcc@1  39.60 ( 39.13)\tAcc@5  66.40 ( 65.52)\n",
      "Epoch: [1][1800/2563]\tTime  0.672 ( 1.607)\tData  0.002 ( 0.939)\tLoss 2.6548e+00 (2.7355e+00)\tAcc@1  42.60 ( 39.21)\tAcc@5  65.60 ( 65.61)\n",
      "Epoch: [1][1850/2563]\tTime  0.669 ( 1.607)\tData  0.002 ( 0.939)\tLoss 2.5287e+00 (2.7309e+00)\tAcc@1  43.00 ( 39.30)\tAcc@5  69.20 ( 65.68)\n",
      "Epoch: [1][1900/2563]\tTime  1.581 ( 1.607)\tData  0.914 ( 0.939)\tLoss 2.4470e+00 (2.7259e+00)\tAcc@1  46.80 ( 39.39)\tAcc@5  70.20 ( 65.77)\n",
      "Epoch: [1][1950/2563]\tTime  1.309 ( 1.607)\tData  0.637 ( 0.939)\tLoss 2.6358e+00 (2.7203e+00)\tAcc@1  42.60 ( 39.50)\tAcc@5  68.80 ( 65.87)\n",
      "Epoch: [1][2000/2563]\tTime  1.124 ( 1.607)\tData  0.452 ( 0.938)\tLoss 2.4955e+00 (2.7158e+00)\tAcc@1  42.80 ( 39.57)\tAcc@5  69.20 ( 65.95)\n",
      "Epoch: [1][2050/2563]\tTime  1.344 ( 1.606)\tData  0.678 ( 0.938)\tLoss 2.7084e+00 (2.7113e+00)\tAcc@1  41.20 ( 39.65)\tAcc@5  68.40 ( 66.04)\n",
      "Epoch: [1][2100/2563]\tTime  1.334 ( 1.606)\tData  0.667 ( 0.937)\tLoss 2.3793e+00 (2.7069e+00)\tAcc@1  42.20 ( 39.74)\tAcc@5  72.60 ( 66.11)\n",
      "Epoch: [1][2150/2563]\tTime  0.767 ( 1.605)\tData  0.098 ( 0.937)\tLoss 2.5851e+00 (2.7030e+00)\tAcc@1  43.00 ( 39.81)\tAcc@5  66.80 ( 66.19)\n",
      "Epoch: [1][2200/2563]\tTime  0.944 ( 1.605)\tData  0.277 ( 0.937)\tLoss 2.3885e+00 (2.6985e+00)\tAcc@1  48.60 ( 39.90)\tAcc@5  74.20 ( 66.27)\n",
      "Epoch: [1][2250/2563]\tTime  0.671 ( 1.605)\tData  0.002 ( 0.936)\tLoss 2.3772e+00 (2.6941e+00)\tAcc@1  48.20 ( 39.98)\tAcc@5  71.40 ( 66.34)\n",
      "Epoch: [1][2300/2563]\tTime  1.057 ( 1.605)\tData  0.392 ( 0.936)\tLoss 2.3987e+00 (2.6895e+00)\tAcc@1  45.00 ( 40.06)\tAcc@5  71.80 ( 66.41)\n",
      "Epoch: [1][2350/2563]\tTime  1.526 ( 1.605)\tData  0.858 ( 0.936)\tLoss 2.4475e+00 (2.6851e+00)\tAcc@1  46.00 ( 40.15)\tAcc@5  72.40 ( 66.48)\n",
      "Epoch: [1][2400/2563]\tTime  2.388 ( 1.605)\tData  1.719 ( 0.937)\tLoss 2.7826e+00 (2.6813e+00)\tAcc@1  39.80 ( 40.22)\tAcc@5  63.40 ( 66.54)\n",
      "Epoch: [1][2450/2563]\tTime  2.556 ( 1.606)\tData  1.840 ( 0.937)\tLoss 2.3159e+00 (2.6770e+00)\tAcc@1  48.40 ( 40.29)\tAcc@5  71.40 ( 66.62)\n",
      "Epoch: [1][2500/2563]\tTime  2.657 ( 1.606)\tData  1.937 ( 0.936)\tLoss 2.6888e+00 (2.6730e+00)\tAcc@1  40.20 ( 40.36)\tAcc@5  64.20 ( 66.68)\n",
      "Epoch: [1][2550/2563]\tTime  2.556 ( 1.606)\tData  1.866 ( 0.936)\tLoss 2.3924e+00 (2.6690e+00)\tAcc@1  45.80 ( 40.44)\tAcc@5  71.60 ( 66.75)\n",
      "Test: [  0/100]\tTime  4.709 ( 4.709)\tLoss 1.9794e+00 (1.9794e+00)\tAcc@1  55.80 ( 55.80)\tAcc@5  81.60 ( 81.60)\n",
      "Test: [ 50/100]\tTime  2.818 ( 1.824)\tLoss 3.6572e+00 (2.6466e+00)\tAcc@1  24.40 ( 39.44)\tAcc@5  47.00 ( 68.25)\n",
      " * Acc@1 37.480 Acc@5 64.506\n",
      "lr: [0.0]\n",
      "CPU times: user 1h 3min 42s, sys: 4min 36s, total: 1h 8min 18s\n",
      "Wall time: 2h 24min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(START_EPOCH, EPOCHS):\n",
    "#     adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, epoch)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc1 = validate(val_loader, model, criterion)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc1 > best_acc1\n",
    "    best_acc1 = max(acc1, best_acc1)\n",
    "\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'arch': ARCH,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_acc1': best_acc1,\n",
    "        'optimizer' : optimizer.state_dict(),\n",
    "    }, is_best)\n",
    "    \n",
    "    scheduler.step()\n",
    "    print('lr: ' + str(scheduler.get_last_lr()))\n",
    "    \n",
    "    writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step = global_step)\n",
    "    \n",
    "    wandb.log({'lr': scheduler.get_last_lr()[0]})\n",
    "    \n",
    "# print(f'{time.time() - start:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "adc68068",
   "metadata": {
    "id": "adc68068"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-91b7584a2265b1f5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-91b7584a2265b1f5\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "writer.close()\n",
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=/data/runs"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "cinic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
